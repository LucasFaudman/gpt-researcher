"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[849],{6164:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"docsSidebar":[{"type":"link","label":"Welcome","href":"/docs/welcome","docId":"welcome","unlisted":false},{"type":"category","label":"Getting Started","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"Introduction","href":"/docs/gpt-researcher/getting-started/introduction","docId":"gpt-researcher/getting-started/introduction","unlisted":false},{"type":"link","label":"How to Choose","href":"/docs/gpt-researcher/getting-started/how-to-choose","docId":"gpt-researcher/getting-started/how-to-choose","unlisted":false},{"type":"link","label":"Getting Started","href":"/docs/gpt-researcher/getting-started/","docId":"gpt-researcher/getting-started/getting-started","unlisted":false},{"type":"link","label":"Run with CLI","href":"/docs/gpt-researcher/getting-started/cli","docId":"gpt-researcher/getting-started/cli","unlisted":false},{"type":"link","label":"Docker: Quickstart","href":"/docs/gpt-researcher/getting-started/getting-started-with-docker","docId":"gpt-researcher/getting-started/getting-started-with-docker","unlisted":false},{"type":"link","label":"Running on Linux","href":"/docs/gpt-researcher/getting-started/linux-deployment","docId":"gpt-researcher/getting-started/linux-deployment","unlisted":false}]},{"type":"category","label":"GPT Researcher","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"PIP Package","href":"/docs/gpt-researcher/gptr/pip-package","docId":"gpt-researcher/gptr/pip-package","unlisted":false},{"type":"link","label":"npm package","href":"/docs/gpt-researcher/gptr/npm-package","docId":"gpt-researcher/gptr/npm-package","unlisted":false},{"type":"link","label":"Agent Example","href":"/docs/gpt-researcher/gptr/example","docId":"gpt-researcher/gptr/example","unlisted":false},{"type":"link","label":"Deep Research \u2728 NEW \u2728","href":"/docs/gpt-researcher/gptr/deep_research","docId":"gpt-researcher/gptr/deep_research","unlisted":false},{"type":"link","label":"Configuration","href":"/docs/gpt-researcher/gptr/config","docId":"gpt-researcher/gptr/config","unlisted":false},{"type":"link","label":"Scraping Options","href":"/docs/gpt-researcher/gptr/scraping","docId":"gpt-researcher/gptr/scraping","unlisted":false},{"type":"link","label":"Querying the Backend","href":"/docs/gpt-researcher/gptr/querying-the-backend","docId":"gpt-researcher/gptr/querying-the-backend","unlisted":false},{"type":"link","label":"Automated Tests","href":"/docs/gpt-researcher/gptr/automated-tests","docId":"gpt-researcher/gptr/automated-tests","unlisted":false},{"type":"link","label":"Troubleshooting","href":"/docs/gpt-researcher/gptr/troubleshooting","docId":"gpt-researcher/gptr/troubleshooting","unlisted":false}]},{"type":"category","label":"Frontend","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Intro to the Frontends","href":"/docs/gpt-researcher/frontend/introduction","docId":"gpt-researcher/frontend/introduction","unlisted":false},{"type":"link","label":"NextJS Frontend","href":"/docs/gpt-researcher/frontend/nextjs-frontend","docId":"gpt-researcher/frontend/nextjs-frontend","unlisted":false},{"type":"link","label":"React Package","href":"/docs/gpt-researcher/frontend/react-package","docId":"gpt-researcher/frontend/react-package","unlisted":false},{"type":"link","label":"Embed Script","href":"/docs/gpt-researcher/frontend/embed-script","docId":"gpt-researcher/frontend/embed-script","unlisted":false},{"type":"link","label":"Vanilla JS Frontend","href":"/docs/gpt-researcher/frontend/vanilla-js-frontend","docId":"gpt-researcher/frontend/vanilla-js-frontend","unlisted":false},{"type":"link","label":"Discord Bot","href":"/docs/gpt-researcher/frontend/discord-bot","docId":"gpt-researcher/frontend/discord-bot","unlisted":false},{"type":"link","label":"Visualizing Websockets","href":"/docs/gpt-researcher/frontend/visualizing-websockets","docId":"gpt-researcher/frontend/visualizing-websockets","unlisted":false}]},{"type":"category","label":"Custom Context","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Tailored Research","href":"/docs/gpt-researcher/context/tailored-research","docId":"gpt-researcher/context/tailored-research","unlisted":false},{"type":"link","label":"Local Documents","href":"/docs/gpt-researcher/context/local-docs","docId":"gpt-researcher/context/local-docs","unlisted":false},{"type":"link","label":"Azure Storage","href":"/docs/gpt-researcher/context/azure-storage","docId":"gpt-researcher/context/azure-storage","unlisted":false},{"type":"link","label":"Filtering by Domain","href":"/docs/gpt-researcher/context/filtering-by-domain","docId":"gpt-researcher/context/filtering-by-domain","unlisted":false},{"type":"link","label":"Vector Stores","href":"/docs/gpt-researcher/context/vector-stores","docId":"gpt-researcher/context/vector-stores","unlisted":false},{"type":"link","label":"Data Ingestion","href":"/docs/gpt-researcher/context/data-ingestion","docId":"gpt-researcher/context/data-ingestion","unlisted":false}]},{"type":"category","label":"Handling Logs","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"All About Logs","href":"/docs/gpt-researcher/handling-logs/all-about-logs","docId":"gpt-researcher/handling-logs/all-about-logs","unlisted":false},{"type":"link","label":"Simple Logs Example","href":"/docs/gpt-researcher/handling-logs/simple-logs-example","docId":"gpt-researcher/handling-logs/simple-logs-example","unlisted":false},{"type":"link","label":"Langsmith Logs","href":"/docs/gpt-researcher/handling-logs/langsmith-logs","docId":"gpt-researcher/handling-logs/langsmith-logs","unlisted":false}]},{"type":"category","label":"LLM Providers","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Configure LLM","href":"/docs/gpt-researcher/llms/","docId":"gpt-researcher/llms/llms","unlisted":false},{"type":"link","label":"Supported LLMs","href":"/docs/gpt-researcher/llms/supported-llms","docId":"gpt-researcher/llms/supported-llms","unlisted":false},{"type":"link","label":"Testing your LLM","href":"/docs/gpt-researcher/llms/testing-your-llm","docId":"gpt-researcher/llms/testing-your-llm","unlisted":false},{"type":"link","label":"Running with Azure","href":"/docs/gpt-researcher/llms/running-with-azure","docId":"gpt-researcher/llms/running-with-azure","unlisted":false},{"type":"link","label":"Running with Ollama","href":"/docs/gpt-researcher/llms/running-with-ollama","docId":"gpt-researcher/llms/running-with-ollama","unlisted":false}]},{"type":"category","label":"Search Engines","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Retrievers","href":"/docs/gpt-researcher/search-engines/retrievers","docId":"gpt-researcher/search-engines/retrievers","unlisted":false},{"type":"link","label":"Testing your Retriever","href":"/docs/gpt-researcher/search-engines/test-your-retriever","docId":"gpt-researcher/search-engines/test-your-retriever","unlisted":false}]},{"type":"category","label":"Multi-Agent Frameworks","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"LangGraph","href":"/docs/gpt-researcher/multi_agents/langgraph","docId":"gpt-researcher/multi_agents/langgraph","unlisted":false}]},{"type":"category","label":"MCP Server","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Getting Started","href":"/docs/gpt-researcher/mcp-server/getting-started","docId":"gpt-researcher/mcp-server/getting-started","unlisted":false},{"type":"link","label":"Advanced Usage","href":"/docs/gpt-researcher/mcp-server/advanced-usage","docId":"gpt-researcher/mcp-server/advanced-usage","unlisted":false},{"type":"link","label":"Claude Desktop Integration","href":"/docs/gpt-researcher/mcp-server/claude-integration","docId":"gpt-researcher/mcp-server/claude-integration","unlisted":false}]},{"type":"category","label":"Examples","items":[{"type":"link","label":"Detailed Report","href":"/docs/examples/detailed_report","docId":"examples/detailed_report","unlisted":false},{"type":"link","label":"Simple Run","href":"/docs/examples/","docId":"examples/examples","unlisted":false},{"type":"link","label":"Hybrid Research","href":"/docs/examples/hybrid_research","docId":"examples/hybrid_research","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"link","label":"Contribute","href":"/docs/contribute","docId":"contribute","unlisted":false},{"type":"link","label":"Roadmap","href":"/docs/roadmap","docId":"roadmap","unlisted":false},{"type":"link","label":"FAQ","href":"/docs/faq","docId":"faq","unlisted":false}],"referenceSideBar":[]},"docs":{"contribute":{"id":"contribute","title":"Contribute","description":"We highly welcome contributions! Please check out contributing if you\'re interested.","sidebar":"docsSidebar"},"examples/detailed_report":{"id":"examples/detailed_report","title":"Detailed Report","description":"Overview","sidebar":"docsSidebar"},"examples/examples":{"id":"examples/examples","title":"Simple Run","description":"Run PIP Package","sidebar":"docsSidebar"},"examples/hybrid_research":{"id":"examples/hybrid_research","title":"Hybrid Research","description":"Introduction","sidebar":"docsSidebar"},"faq":{"id":"faq","title":"FAQ","description":"How do I get started?","sidebar":"docsSidebar"},"gpt-researcher/context/azure-storage":{"id":"gpt-researcher/context/azure-storage","title":"Azure Storage","description":"If you want to use Azure Blob Storage as the source for your GPT Researcher report context, follow these steps:","sidebar":"docsSidebar"},"gpt-researcher/context/data-ingestion":{"id":"gpt-researcher/context/data-ingestion","title":"Data Ingestion","description":"When you\'re dealing with a large amount of context data, you may want to start meditating upon a standalone process for data ingestion.","sidebar":"docsSidebar"},"gpt-researcher/context/filtering-by-domain":{"id":"gpt-researcher/context/filtering-by-domain","title":"Filtering by Domain","description":"You can filter web search results by specific domains when using either the Tavily or Google Search retrievers. This functionality is available across all interfaces - pip package, NextJS frontend, and vanilla JS frontend.","sidebar":"docsSidebar"},"gpt-researcher/context/local-docs":{"id":"gpt-researcher/context/local-docs","title":"Local Documents","description":"Just Local Docs","sidebar":"docsSidebar"},"gpt-researcher/context/tailored-research":{"id":"gpt-researcher/context/tailored-research","title":"Tailored Research","description":"The GPT Researcher package allows you to tailor the research to your needs such as researching on specific sources (URLs) or local documents, and even specify the agent prompt instruction upon which the research is conducted.","sidebar":"docsSidebar"},"gpt-researcher/context/vector-stores":{"id":"gpt-researcher/context/vector-stores","title":"Vector Stores","description":"The GPT Researcher package allows you to integrate with existing langchain vector stores that have been populated.","sidebar":"docsSidebar"},"gpt-researcher/frontend/discord-bot":{"id":"gpt-researcher/frontend/discord-bot","title":"Discord Bot","description":"Intro","sidebar":"docsSidebar"},"gpt-researcher/frontend/embed-script":{"id":"gpt-researcher/frontend/embed-script","title":"Embed Script","description":"The embed script enables you to embed the latest GPTR NextJS app into your web app.","sidebar":"docsSidebar"},"gpt-researcher/frontend/introduction":{"id":"gpt-researcher/frontend/introduction","title":"Intro to the Frontends","description":"The frontends enhance GPT-Researcher by providing:","sidebar":"docsSidebar"},"gpt-researcher/frontend/nextjs-frontend":{"id":"gpt-researcher/frontend/nextjs-frontend","title":"NextJS Frontend","description":"This frontend project aims to enhance the user experience of GPT Researcher, providing an intuitive and efficient interface for automated research. It offers two deployment options to suit different needs and environments.","sidebar":"docsSidebar"},"gpt-researcher/frontend/react-package":{"id":"gpt-researcher/frontend/react-package","title":"React Package","description":"The GPTR React package is an abstraction on top of the NextJS app meant to empower users to easily import the GPTR frontend into any React App. The package is available on npm.","sidebar":"docsSidebar"},"gpt-researcher/frontend/vanilla-js-frontend":{"id":"gpt-researcher/frontend/vanilla-js-frontend","title":"Vanilla JS Frontend","description":"The VanillaJS frontend is a lightweight solution leveraging FastAPI to serve static files.","sidebar":"docsSidebar"},"gpt-researcher/frontend/visualizing-websockets":{"id":"gpt-researcher/frontend/visualizing-websockets","title":"Visualizing Websockets","description":"The GPTR Frontend is powered by Websockets streaming back from the Backend. This allows for real-time updates on the status of your research tasks, as well as the ability to interact with the Backend directly from the Frontend.","sidebar":"docsSidebar"},"gpt-researcher/getting-started/cli":{"id":"gpt-researcher/getting-started/cli","title":"Run with CLI","description":"This command-line interface (CLI) tool allows you to generate research reports using the GPTResearcher class. It provides an easy way to conduct research on various topics and generate different types of reports.","sidebar":"docsSidebar"},"gpt-researcher/getting-started/getting-started":{"id":"gpt-researcher/getting-started/getting-started","title":"Getting Started","description":"Step 0 - Install Python 3.11 or later. See here for a step-by-step guide.","sidebar":"docsSidebar"},"gpt-researcher/getting-started/getting-started-with-docker":{"id":"gpt-researcher/getting-started/getting-started-with-docker","title":"Docker: Quickstart","description":"Step 1 - Install & Open Docker Desktop","sidebar":"docsSidebar"},"gpt-researcher/getting-started/how-to-choose":{"id":"gpt-researcher/getting-started/how-to-choose","title":"How to Choose","description":"GPT Researcher is a powerful autonomous research agent designed to enhance and streamline your research processes. Whether you\'re a developer looking to integrate research capabilities into your project or an end-user seeking a comprehensive research solution, GPT Researcher offers flexible options to meet your needs.","sidebar":"docsSidebar"},"gpt-researcher/getting-started/introduction":{"id":"gpt-researcher/getting-started/introduction","title":"Introduction","description":"Official Website","sidebar":"docsSidebar"},"gpt-researcher/getting-started/linux-deployment":{"id":"gpt-researcher/getting-started/linux-deployment","title":"Running on Linux","description":"This guide will walk you through the process of deploying GPT Researcher on a Linux server.","sidebar":"docsSidebar"},"gpt-researcher/gptr/automated-tests":{"id":"gpt-researcher/gptr/automated-tests","title":"Automated Tests","description":"Automated Testing with Github Actions","sidebar":"docsSidebar"},"gpt-researcher/gptr/config":{"id":"gpt-researcher/gptr/config","title":"Configuration","description":"The config.py enables you to customize GPT Researcher to your specific needs and preferences.","sidebar":"docsSidebar"},"gpt-researcher/gptr/deep_research":{"id":"gpt-researcher/gptr/deep_research","title":"Deep Research \u2728 NEW \u2728","description":"With the latest \\"Deep Research\\" trend in the AI community, we\'re excited to implement our own Open source deep research capability! Introducing GPT Researcher\'s Deep Research - an advanced recursive research system that explores topics with unprecedented depth and breadth.","sidebar":"docsSidebar"},"gpt-researcher/gptr/example":{"id":"gpt-researcher/gptr/example","title":"Agent Example","description":"If you\'re interested in using GPT Researcher as a standalone agent, you can easily import it into any existing Python project. Below, is an example of calling the agent to generate a research report:","sidebar":"docsSidebar"},"gpt-researcher/gptr/npm-package":{"id":"gpt-researcher/gptr/npm-package","title":"npm package","description":"The gpt-researcher npm package is a WebSocket client for interacting with GPT Researcher.","sidebar":"docsSidebar"},"gpt-researcher/gptr/pip-package":{"id":"gpt-researcher/gptr/pip-package","title":"PIP Package","description":"PyPI version","sidebar":"docsSidebar"},"gpt-researcher/gptr/querying-the-backend":{"id":"gpt-researcher/gptr/querying-the-backend","title":"Querying the Backend","description":"Introduction","sidebar":"docsSidebar"},"gpt-researcher/gptr/scraping":{"id":"gpt-researcher/gptr/scraping","title":"Scraping Options","description":"GPT Researcher now offers various methods for web scraping: static scraping with BeautifulSoup, dynamic scraping with Selenium, and High scale scraping with Tavily Extract. This document explains how to switch between these methods and the benefits of each approach.","sidebar":"docsSidebar"},"gpt-researcher/gptr/troubleshooting":{"id":"gpt-researcher/gptr/troubleshooting","title":"Troubleshooting","description":"We\'re constantly working to provide a more stable version. If you\'re running into any issues, please first check out the resolved issues or ask us via our Discord community.","sidebar":"docsSidebar"},"gpt-researcher/handling-logs/all-about-logs":{"id":"gpt-researcher/handling-logs/all-about-logs","title":"All About Logs","description":"This document explains how to interpret the log files generated for each report. These logs provide a detailed record of the research process, from initial task planning to the gathering of information, and finally, the report writing process. Reports may change over time as new features are developed.","sidebar":"docsSidebar"},"gpt-researcher/handling-logs/langsmith-logs":{"id":"gpt-researcher/handling-logs/langsmith-logs","title":"Langsmith Logs","description":"With the help of Langsmith, you can easily visualize logs on cost and errors within your Langsmith Dashboard (calculated per LLM call or grouped by project)","sidebar":"docsSidebar"},"gpt-researcher/handling-logs/simple-logs-example":{"id":"gpt-researcher/handling-logs/simple-logs-example","title":"Simple Logs Example","description":"Here is a snippet of code to help you handle the streaming logs of your Research tasks.","sidebar":"docsSidebar"},"gpt-researcher/llms/llms":{"id":"gpt-researcher/llms/llms","title":"Configure LLM","description":"As described in the introduction, the default LLM and embedding is OpenAI due to its superior performance and speed.","sidebar":"docsSidebar"},"gpt-researcher/llms/running-with-azure":{"id":"gpt-researcher/llms/running-with-azure","title":"Running with Azure","description":"Example: Azure OpenAI Configuration","sidebar":"docsSidebar"},"gpt-researcher/llms/running-with-ollama":{"id":"gpt-researcher/llms/running-with-ollama","title":"Running with Ollama","description":"Ollama is a platform that allows you to deploy and manage custom language models. This guide will walk you through deploying a custom language model on Ollama.","sidebar":"docsSidebar"},"gpt-researcher/llms/supported-llms":{"id":"gpt-researcher/llms/supported-llms","title":"Supported LLMs","description":"The following LLMs are supported by GPTR (though you\'ll need to install the relevant langchain package separately if you\'re not using OpenAI).","sidebar":"docsSidebar"},"gpt-researcher/llms/testing-your-llm":{"id":"gpt-researcher/llms/testing-your-llm","title":"Testing your LLM","description":"Here is a snippet of code to help you verify that your LLM-related environment variables are set up correctly.","sidebar":"docsSidebar"},"gpt-researcher/mcp-server/advanced-usage":{"id":"gpt-researcher/mcp-server/advanced-usage","title":"Advanced Usage","description":"This guide covers advanced usage scenarios and configurations for the GPT Researcher MCP Server.","sidebar":"docsSidebar"},"gpt-researcher/mcp-server/claude-integration":{"id":"gpt-researcher/mcp-server/claude-integration","title":"Claude Desktop Integration","description":"This guide specifically focuses on how to integrate your locally running GPT Researcher MCP server with the Claude desktop application for Mac, providing a seamless research experience within the Claude interface.","sidebar":"docsSidebar"},"gpt-researcher/mcp-server/getting-started":{"id":"gpt-researcher/mcp-server/getting-started","title":"Getting Started","description":"The GPT Researcher MCP Server provides Model Context Protocol (MCP) integration for GPT Researcher, allowing AI assistants to perform autonomous, comprehensive web research and generate reports via the MCP protocol.","sidebar":"docsSidebar"},"gpt-researcher/multi_agents/langgraph":{"id":"gpt-researcher/multi_agents/langgraph","title":"LangGraph","description":"LangGraph is a library for building stateful, multi-actor applications with LLMs.","sidebar":"docsSidebar"},"gpt-researcher/retrievers/mcp-configs":{"id":"gpt-researcher/retrievers/mcp-configs","title":"MCP Integration with GPT Researcher","description":"The Model Context Protocol (MCP) enables GPT Researcher to connect with diverse data sources and tools through a standardized interface. GPT Researcher features an intelligent two-stage MCP approach that automatically selects the best tools and generates contextual research, powered by LangChain\'s MCP adapters for seamless integration."},"gpt-researcher/search-engines/retrievers":{"id":"gpt-researcher/search-engines/retrievers","title":"Retrievers","description":"Retrievers are search engines used to find the most relevant documents for a given research task.","sidebar":"docsSidebar"},"gpt-researcher/search-engines/test-your-retriever":{"id":"gpt-researcher/search-engines/test-your-retriever","title":"Testing your Retriever","description":"To test your retriever, you can use the following code snippet. The script will search for a sub-query and display the search results.","sidebar":"docsSidebar"},"reference/config/config":{"id":"reference/config/config","title":"config.config","description":"Configuration class to store the state of bools for different scripts access."},"reference/config/singleton":{"id":"reference/config/singleton","title":"config.singleton","description":"The singleton metaclass for ensuring only one instance of a class."},"reference/processing/html":{"id":"reference/processing/html","title":"processing.html","description":"HTML processing functions"},"reference/processing/text":{"id":"reference/processing/text","title":"processing.text","description":"Text processing functions"},"roadmap":{"id":"roadmap","title":"Roadmap","description":"We\'re constantly working on additional features and improvements to our products and services. We\'re also working on new products and services to help you build better AI applications using GPT Researcher.","sidebar":"docsSidebar"},"welcome":{"id":"welcome","title":"Welcome","description":"Hey there! \ud83d\udc4b","sidebar":"docsSidebar"}}}}')}}]);