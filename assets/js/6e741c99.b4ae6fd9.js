"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1103],{841:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>c,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"gpt-researcher/retrievers/mcp-configs","title":"MCP Integration","description":"The Model Context Protocol (MCP) enables GPT Researcher to connect with diverse data sources and tools through a standardized interface. GPT Researcher features an intelligent two-stage MCP approach that automatically selects the best tools and generates contextual research, powered by LangChain\'s MCP adapters for seamless integration.","source":"@site/docs/gpt-researcher/retrievers/mcp-configs.mdx","sourceDirName":"gpt-researcher/retrievers","slug":"/gpt-researcher/retrievers/mcp-configs","permalink":"/docs/gpt-researcher/retrievers/mcp-configs","draft":false,"unlisted":false,"editUrl":"https://github.com/assafelovic/gpt-researcher/tree/master/docs/docs/gpt-researcher/retrievers/mcp-configs.mdx","tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Search Engines","permalink":"/docs/gpt-researcher/search-engines/"},"next":{"title":"Testing your Retriever","permalink":"/docs/gpt-researcher/search-engines/test-your-retriever"}}');var i=r(4848),t=r(8453);const c={},a="MCP Integration",o={},l=[{value:"How MCP Works in GPT Researcher",id:"how-mcp-works-in-gpt-researcher",level:2},{value:"MCP Research Flow",id:"mcp-research-flow",level:2},{value:"Flow Breakdown:",id:"flow-breakdown",level:3},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Essential Configuration: Enabling MCP",id:"essential-configuration-enabling-mcp",level:2},{value:"Pure MCP Research",id:"pure-mcp-research",level:3},{value:"Hybrid Strategy (Recommended)",id:"hybrid-strategy-recommended",level:3},{value:"Quick Start",id:"quick-start",level:2},{value:"Configuration Structure",id:"configuration-structure",level:2},{value:"Examples",id:"examples",level:2},{value:"News and Web Research with Tavily",id:"news-and-web-research-with-tavily",level:3},{value:"Code Research with GitHub",id:"code-research-with-github",level:3},{value:"Academic Research with Hybrid Strategy",id:"academic-research-with-hybrid-strategy",level:3},{value:"Multi-Server Research: Comprehensive Market Analysis",id:"multi-server-research-comprehensive-market-analysis",level:2},{value:"E-commerce Competitive Analysis",id:"e-commerce-competitive-analysis",level:3},{value:"Remote MCP Server",id:"remote-mcp-server",level:2},{value:"Combining MCP with Web Search",id:"combining-mcp-with-web-search",level:2},{value:"Complete Working Example",id:"complete-working-example",level:2},{value:"Retriever Strategy Comparison",id:"retriever-strategy-comparison",level:2},{value:"Advanced Configuration",id:"advanced-configuration",level:2},{value:"Research Strategies",id:"research-strategies",level:3},{value:"Environment Variable Configuration",id:"environment-variable-configuration",level:3},{value:"Custom Tool Selection",id:"custom-tool-selection",level:3},{value:"Connection Type Detection",id:"connection-type-detection",level:3},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Common Issues",id:"common-issues",level:3},{value:"Debug Mode",id:"debug-mode",level:3},{value:"Testing Your Setup",id:"testing-your-setup",level:3},{value:"Best Practices",id:"best-practices",level:2}];function d(e){const n={a:"a",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"mcp-integration",children:"MCP Integration"})}),"\n",(0,i.jsxs)(n.p,{children:["The Model Context Protocol (MCP) enables GPT Researcher to connect with diverse data sources and tools through a standardized interface. GPT Researcher features an intelligent two-stage MCP approach that automatically selects the best tools and generates contextual research, powered by LangChain's ",(0,i.jsx)(n.a,{href:"https://github.com/langchain-ai/langchain-mcp-adapters",children:"MCP adapters"})," for seamless integration."]}),"\n",(0,i.jsx)(n.h2,{id:"how-mcp-works-in-gpt-researcher",children:"How MCP Works in GPT Researcher"}),"\n",(0,i.jsxs)(n.p,{children:["GPT Researcher uses a ",(0,i.jsx)(n.strong,{children:"two stage intelligent approach"})," for MCP integration:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stage 1: Smart Tool Selection"})," - LLM analyzes your query and available MCP servers to select the most relevant tools"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stage 2: Contextual Research"})," - LLM uses selected tools with dynamically generated, query specific arguments"]}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["This happens automatically behind the scenes, optimized for the best balance of speed, cost, and research quality. The integration leverages the ",(0,i.jsx)(n.a,{href:"https://github.com/langchain-ai/langchain-mcp-adapters",children:"langchain-mcp-adapters"})," library, ensuring compatibility with the growing ecosystem of MCP tool servers."]}),"\n",(0,i.jsx)(n.h2,{id:"mcp-research-flow",children:"MCP Research Flow"}),"\n",(0,i.jsxs)(n.p,{children:["The following diagram illustrates the hybrid strategy using ",(0,i.jsx)(n.code,{children:"RETRIEVER=tavily,mcp"})," as an example:"]}),"\n",(0,i.jsx)("img",{width:"662",alt:"Screenshot 2025-06-06 at 14 38 04",src:"https://cowriter-images.s3.us-east-1.amazonaws.com/Screenshot+2025-06-06+at+14.38.04.png"}),"\n",(0,i.jsx)(n.h3,{id:"flow-breakdown",children:"Flow Breakdown:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Configuration"}),": Set ",(0,i.jsx)(n.code,{children:"RETRIEVER"})," environment variable to enable MCP"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Strategy Selection"}),": Choose pure MCP or hybrid approach"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Initialization"}),": GPT Researcher loads your ",(0,i.jsx)(n.code,{children:"mcp_configs"})]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stage 1"}),": LLM intelligently selects the most relevant tools from available MCP servers"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Stage 2"}),": LLM executes research using selected tools with query-specific arguments"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Hybrid Processing"}),": If using hybrid strategy, combines MCP results with web search"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Report Generation"}),": Synthesizes all findings into a comprehensive report"]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.p,{children:"MCP support is included with GPT Researcher installation:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install gpt-researcher\n# All MCP dependencies are included automatically\n"})}),"\n",(0,i.jsx)(n.h2,{id:"essential-configuration-enabling-mcp",children:"Essential Configuration: Enabling MCP"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Important:"})," To use MCP with GPT Researcher, you must set the ",(0,i.jsx)(n.code,{children:"RETRIEVER"})," environment variable:"]}),"\n",(0,i.jsx)(n.h3,{id:"pure-mcp-research",children:"Pure MCP Research"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"export RETRIEVER=mcp\n"})}),"\n",(0,i.jsx)(n.h3,{id:"hybrid-strategy-recommended",children:"Hybrid Strategy (Recommended)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Combines web search with MCP for comprehensive research\nexport RETRIEVER=tavily,mcp\n\n# Alternative hybrid combinations\nexport RETRIEVER=tavily,mcp\nexport RETRIEVER=google,mcp,arxiv\n"})}),"\n",(0,i.jsx)(n.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from gpt_researcher import GPTResearcher\nimport os\n\n# Set retriever to enable MCP\nos.environ["RETRIEVER"] = "tavily,mcp"  # Hybrid approach\n\n# Simple MCP configuration - works automatically\nresearcher = GPTResearcher(\n    query="How does React\'s useState hook work?",\n    mcp_configs=[\n        {\n            "name": "github_api"\n            "command": "npx",\n            "args": ["-y", "@modelcontextprotocol/server-github"],\n            "env": {"GITHUB_TOKEN": os.getenv("GITHUB_TOKEN")}\n        }\n    ]\n)\n\ncontext = await researcher.conduct_research()\nreport = await researcher.write_report()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"configuration-structure",children:"Configuration Structure"}),"\n",(0,i.jsx)(n.p,{children:"Each MCP configuration dictionary supports these keys:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Key"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Example"}),(0,i.jsx)(n.th,{children:"Required"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"name"})}),(0,i.jsx)(n.td,{children:"Identifier for the MCP server"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"github"'})}),(0,i.jsx)(n.td,{children:"Yes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"command"})}),(0,i.jsx)(n.td,{children:"Command to start the server"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"python"'})}),(0,i.jsx)(n.td,{children:"Yes*"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"args"})}),(0,i.jsx)(n.td,{children:"Arguments for the server command"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'["-m", "my_server"]'})}),(0,i.jsx)(n.td,{children:"Yes*"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"env"})}),(0,i.jsx)(n.td,{children:"Environment variables for the server"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'{"API_KEY": "key"}'})}),(0,i.jsx)(n.td,{children:"No"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"connection_url"})}),(0,i.jsx)(n.td,{children:"URL for remote connections"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"wss://api.example.com"'})}),(0,i.jsx)(n.td,{children:"Yes**"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"connection_type"})}),(0,i.jsx)(n.td,{children:"Connection type (auto-detected)"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"websocket"'})}),(0,i.jsx)(n.td,{children:"No"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"connection_token"})}),(0,i.jsx)(n.td,{children:"Authentication token"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"bearer_token"'})}),(0,i.jsx)(n.td,{children:"No"})]})]})]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Local servers"}),": Require ",(0,i.jsx)(n.code,{children:"name"}),", ",(0,i.jsx)(n.code,{children:"command"}),", and ",(0,i.jsx)(n.code,{children:"args"}),(0,i.jsx)(n.br,{}),"\n",(0,i.jsx)(n.strong,{children:"Remote servers"}),": Require ",(0,i.jsx)(n.code,{children:"name"})," and ",(0,i.jsx)(n.code,{children:"connection_url"})]}),"\n",(0,i.jsx)(n.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsx)(n.h3,{id:"news-and-web-research-with-tavily",children:"News and Web Research with Tavily"}),"\n",(0,i.jsx)(n.p,{children:"Perfect for current events, market research, and general information gathering:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from gpt_researcher import GPTResearcher\nimport os\n\n# Enable hybrid research: web search + MCP\nos.environ["RETRIEVER"] = "tavily,mcp"\n\nresearcher = GPTResearcher(\n    query="What are the latest updates in the NBA playoffs?",\n    mcp_configs=[\n        {\n            "name": "tavily",\n            "command": "npx",\n            "args": ["-y", "tavily-mcp@0.1.2"],\n            "env": {\n                "TAVILY_API_KEY": os.getenv("TAVILY_API_KEY")\n            }\n        }\n    ]\n)\n\ncontext = await researcher.conduct_research()\nreport = await researcher.write_report()\n'})}),"\n",(0,i.jsx)(n.h3,{id:"code-research-with-github",children:"Code Research with GitHub"}),"\n",(0,i.jsx)(n.p,{children:"Ideal for technical documentation, code examples, and software development research:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Pure MCP research for technical queries\nos.environ["RETRIEVER"] = "mcp"\n\nresearcher = GPTResearcher(\n    query="What are the key features and implementation of React\'s useState hook? How has it evolved in recent versions?",\n    mcp_configs=[\n        {\n            "name": "github",\n            "command": "npx",\n            "args": ["-y", "@modelcontextprotocol/server-github"],\n            "env": {\n                "GITHUB_PERSONAL_ACCESS_TOKEN": os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN")\n            }\n        }\n    ]\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"academic-research-with-hybrid-strategy",children:"Academic Research with Hybrid Strategy"}),"\n",(0,i.jsx)(n.p,{children:"Combining academic papers with MCP tools:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Academic + MCP hybrid approach\nos.environ["RETRIEVER"] = "arxiv,semantic_scholar,mcp"\n\nresearcher = GPTResearcher(\n    query="Analyze the latest developments in quantum error correction algorithms",\n    mcp_configs=[\n        {\n            "name": "quantum_research",\n            "command": "python",\n            "args": ["quantum_mcp_server.py"],\n            "env": {\n                "ARXIV_API_KEY": os.getenv("ARXIV_API_KEY"),\n                "RESEARCH_DB_PATH": "/path/to/quantum_papers.db"\n            }\n        }\n    ]\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"multi-server-research-comprehensive-market-analysis",children:"Multi-Server Research: Comprehensive Market Analysis"}),"\n",(0,i.jsx)(n.p,{children:"Here's a real-world example combining multiple MCP servers for comprehensive business intelligence:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from gpt_researcher import GPTResearcher\nimport os\n\n# Multi-retriever hybrid strategy for comprehensive coverage\nos.environ["RETRIEVER"] = "tavily,google,mcp"\n\n# Multi-domain research combining news, code, and financial data\nresearcher = GPTResearcher(\n    query="Analyze Tesla\'s Q4 2024 performance, including stock trends, recent innovations, and market sentiment",\n    mcp_configs=[\n        # Financial data and stock analysis\n        {\n            "name": "financial_data",\n            "command": "python",\n            "args": ["financial_mcp_server.py"],\n            "env": {\n                "ALPHA_VANTAGE_KEY": os.getenv("ALPHA_VANTAGE_KEY"),\n                "YAHOO_FINANCE_KEY": os.getenv("YAHOO_FINANCE_KEY")\n            }\n        },\n        # News and market sentiment\n        {\n            "name": "news_research",\n            "command": "npx",\n            "args": ["-y", "tavily-mcp@0.1.2"],\n            "env": {\n                "TAVILY_API_KEY": os.getenv("TAVILY_API_KEY")\n            }\n        },\n        # Technical innovations and patents\n        {\n            "name": "github_research",\n            "command": "npx",\n            "args": ["-y", "@modelcontextprotocol/server-github"],\n            "env": {\n                "GITHUB_PERSONAL_ACCESS_TOKEN": os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN")\n            }\n        },\n        # Academic research and papers\n        {\n            "name": "academic_papers",\n            "command": "python",\n            "args": ["arxiv_mcp_server.py"],\n            "env": {\n                "ARXIV_API_KEY": os.getenv("ARXIV_API_KEY")\n            }\n        }\n    ]\n)\n\n# GPT Researcher automatically orchestrates all servers\ncontext = await researcher.conduct_research()\nreport = await researcher.write_report()\n\nprint(f"Generated comprehensive report using {len(researcher.mcp_configs)} MCP servers")\nprint(f"Research cost: ${researcher.get_costs():.4f}")\n'})}),"\n",(0,i.jsx)(n.p,{children:"This example demonstrates how GPT Researcher intelligently:"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Selects relevant tools"})," from each server based on the query"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Coordinates multi-domain research"})," across financial, news, technical, and academic sources"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Synthesizes information"})," from different domains into a cohesive analysis"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Optimizes performance"})," by using only the most relevant tools from each server"]}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"e-commerce-competitive-analysis",children:"E-commerce Competitive Analysis"}),"\n",(0,i.jsx)(n.p,{children:"Another practical multi-server scenario for business research:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Comprehensive hybrid strategy\nos.environ["RETRIEVER"] = "tavily,bing,exa,mcp"\n\nresearcher = GPTResearcher(\n    query="Comprehensive competitive analysis of sustainable fashion brands in 2024",\n    mcp_configs=[\n        # Web trends and consumer sentiment\n        {\n            "name": "web_trends",\n            "command": "npx",\n            "args": ["-y", "tavily-mcp@0.1.2"],\n            "env": {"TAVILY_API_KEY": os.getenv("TAVILY_API_KEY")}\n        },\n        # Social media analytics\n        {\n            "name": "social_analytics",\n            "command": "python",\n            "args": ["social_mcp_server.py"],\n            "env": {\n                "TWITTER_BEARER_TOKEN": os.getenv("TWITTER_BEARER_TOKEN"),\n                "INSTAGRAM_ACCESS_TOKEN": os.getenv("INSTAGRAM_ACCESS_TOKEN")\n            }\n        },\n        # Patent and innovation research\n        {\n            "name": "patent_research",\n            "command": "python",\n            "args": ["patent_mcp_server.py"],\n            "env": {"USPTO_API_KEY": os.getenv("USPTO_API_KEY")}\n        }\n    ]\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"remote-mcp-server",children:"Remote MCP Server"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Enable MCP with web search fallback\nos.environ["RETRIEVER"] = "tavily,mcp"\n\nresearcher = GPTResearcher(\n    query="Latest AI research papers on transformer architectures",\n    mcp_configs=[\n        {\n            "name": "arxiv_api",\n            "connection_url": "wss://mcp.arxiv.org/ws",  # Auto-detects WebSocket\n            "connection_token": os.getenv("ARXIV_TOKEN"),\n        }\n    ]\n)\n'})}),"\n",(0,i.jsx)(n.h2,{id:"combining-mcp-with-web-search",children:"Combining MCP with Web Search"}),"\n",(0,i.jsx)(n.p,{children:"MCP works seamlessly alongside traditional web search for comprehensive research:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'from gpt_researcher import GPTResearcher\n\n# Hybrid strategy: combines web search with MCP automatically\nos.environ["RETRIEVER"] = "tavily,mcp"\n\nresearcher = GPTResearcher(\n    query="Impact of AI on software development practices",\n    # MCP will be used alongside web search automatically\n    mcp_configs=[\n        {\n            "name": "github",\n            "command": "npx",\n            "args": ["-y", "@modelcontextprotocol/server-github"],\n            "env": {"GITHUB_TOKEN": os.getenv("GITHUB_TOKEN")}\n        }\n    ]\n)\n\n# This uses both MCP (for code examples) and web search (for articles/news)\ncontext = await researcher.conduct_research()\n'})}),"\n",(0,i.jsx)(n.h2,{id:"complete-working-example",children:"Complete Working Example"}),"\n",(0,i.jsx)(n.p,{children:"Here's a production-ready example demonstrating MCP integration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import asyncio\nimport os\nfrom gpt_researcher import GPTResearcher\n\nasync def main():\n    # Set up environment\n    os.environ["GITHUB_PERSONAL_ACCESS_TOKEN"] = "your_github_token"\n    os.environ["OPENAI_API_KEY"] = "your_openai_key"\n    os.environ["TAVILY_API_KEY"] = "your_tavily_key"\n    \n    # Enable hybrid research strategy\n    os.environ["RETRIEVER"] = "tavily,mcp"\n    \n    # Create researcher with multi-server MCP configuration\n    researcher = GPTResearcher(\n        query="How are leading tech companies implementing AI safety measures in 2024?",\n        mcp_configs=[\n            # Code repositories and technical implementations\n            {\n                "name": "github",\n                "command": "npx",\n                "args": ["-y", "@modelcontextprotocol/server-github"],\n                "env": {\n                    "GITHUB_PERSONAL_ACCESS_TOKEN": os.getenv("GITHUB_PERSONAL_ACCESS_TOKEN")\n                }\n            },\n            # Current news and industry reports\n            {\n                "name": "tavily",\n                "command": "npx",\n                "args": ["-y", "tavily-mcp@0.1.2"],\n                "env": {\n                    "TAVILY_API_KEY": os.getenv("TAVILY_API_KEY")\n                }\n            }\n        ],\n        verbose=True  # See the intelligent research process\n    )\n    \n    print("\ud83d\udd0d Starting multi-source research...")\n    \n    # Intelligent tool selection and research happens automatically\n    context = await researcher.conduct_research()\n    \n    print("\ud83d\udcdd Generating comprehensive report...")\n    report = await researcher.write_report()\n    \n    print("\u2705 Research complete!")\n    print(f"\ud83d\udcca Report length: {len(report)} characters")\n    print(f"\ud83d\udcb0 Total cost: ${researcher.get_costs():.4f}")\n    \n    # Save the report\n    with open("ai_safety_research.md", "w") as f:\n        f.write(report)\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})}),"\n",(0,i.jsx)(n.h2,{id:"retriever-strategy-comparison",children:"Retriever Strategy Comparison"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Strategy"}),(0,i.jsx)(n.th,{children:"Use Case"}),(0,i.jsx)(n.th,{children:"Performance"}),(0,i.jsx)(n.th,{children:"Coverage"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"RETRIEVER=mcp"})}),(0,i.jsx)(n.td,{children:"Specialized domains, structured data"}),(0,i.jsx)(n.td,{children:"\u26a1 Fast"}),(0,i.jsx)(n.td,{children:"\ud83c\udfaf Focused"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"RETRIEVER=tavily,mcp"})}),(0,i.jsx)(n.td,{children:"General research with specialized tools"}),(0,i.jsx)(n.td,{children:"\u2696\ufe0f Balanced"}),(0,i.jsx)(n.td,{children:"\ud83c\udf10 Comprehensive"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"RETRIEVER=google,arxiv,tavily,mcp"})}),(0,i.jsx)(n.td,{children:"Maximum coverage, redundancy"}),(0,i.jsx)(n.td,{children:"\ud83d\udc0c Slower"}),(0,i.jsx)(n.td,{children:"\ud83c\udf0d Extensive"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"RETRIEVER=arxiv,mcp"})}),(0,i.jsx)(n.td,{children:"Academic + specialized research"}),(0,i.jsx)(n.td,{children:"\u26a1 Fast"}),(0,i.jsx)(n.td,{children:"\ud83c\udf93 Academic-focused"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"advanced-configuration",children:"Advanced Configuration"}),"\n",(0,i.jsx)(n.h3,{id:"research-strategies",children:"Research Strategies"}),"\n",(0,i.jsx)(n.p,{children:"For advanced users who need more control over how MCP research is executed:"}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Strategy"}),(0,i.jsx)(n.th,{children:"Description"}),(0,i.jsx)(n.th,{children:"Use Case"}),(0,i.jsx)(n.th,{children:"Performance"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"fast"'})}),(0,i.jsx)(n.td,{children:"Run MCP once with main query (default)"}),(0,i.jsx)(n.td,{children:"Most research needs"}),(0,i.jsx)(n.td,{children:"\u26a1 Optimal"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"deep"'})}),(0,i.jsx)(n.td,{children:"Run MCP for all sub-queries"}),(0,i.jsx)(n.td,{children:"Comprehensive analysis"}),(0,i.jsx)(n.td,{children:"\ud83d\udd0d Thorough"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:'"disabled"'})}),(0,i.jsx)(n.td,{children:"Skip MCP entirely"}),(0,i.jsx)(n.td,{children:"Web-only research"}),(0,i.jsx)(n.td,{children:"\u26a1 Fastest"})]})]})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Default behavior (recommended for most use cases)\nos.environ["RETRIEVER"] = "tavily,mcp"\nresearcher = GPTResearcher(\n    query="Analyze Tesla\'s performance",\n    mcp_configs=[...]\n)\n\n# For comprehensive analysis (advanced)\nos.environ["MCP_STRATEGY"] = "deep"\nresearcher = GPTResearcher(\n    query="Comprehensive renewable energy analysis",\n    mcp_configs=[...]\n)\n\n# For web-only research (advanced)\nos.environ["RETRIEVER"] = "tavily"  # Excludes MCP entirely\n'})}),"\n",(0,i.jsx)(n.h3,{id:"environment-variable-configuration",children:"Environment Variable Configuration"}),"\n",(0,i.jsx)(n.p,{children:"Set global defaults using environment variables:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Essential: Enable MCP\nexport RETRIEVER=tavily,mcp\n\n# Advanced: Set MCP strategy\nexport MCP_STRATEGY=deep\n\n# Or in .env file\nRETRIEVER=tavily,mcp\nMCP_STRATEGY=fast\nMCP_AUTO_TOOL_SELECTION=true\n"})}),"\n",(0,i.jsx)(n.h3,{id:"custom-tool-selection",children:"Custom Tool Selection"}),"\n",(0,i.jsx)(n.p,{children:"Enable automatic tool selection for servers with multiple tools:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# Environment variable approach\nos.environ["MCP_AUTO_TOOL_SELECTION"] = "true"\nos.environ["RETRIEVER"] = "mcp"\n\nresearcher = GPTResearcher(\n    query="your query",\n    mcp_configs=[\n        {\n            "command": "python",\n            "args": ["multi_tool_server.py"]\n            # AI will choose the best tool automatically\n        }\n    ]\n)\n'})}),"\n",(0,i.jsx)(n.h3,{id:"connection-type-detection",children:"Connection Type Detection"}),"\n",(0,i.jsx)(n.p,{children:"GPT Researcher automatically detects connection types:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# WebSocket (detected from wss:// prefix)\n{"connection_url": "wss://api.example.com/mcp"}\n\n# HTTP (detected from https:// prefix)  \n{"connection_url": "https://api.example.com/mcp"}\n\n# Stdio (default when no URL provided)\n{"command": "python", "args": ["server.py"]}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.h3,{id:"common-issues",children:"Common Issues"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'"No retriever specified" or "MCP not working"'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Solution:"})," Set ",(0,i.jsx)(n.code,{children:"RETRIEVER=mcp"})," or ",(0,i.jsx)(n.code,{children:"RETRIEVER=tavily,mcp"})]}),"\n",(0,i.jsxs)(n.li,{children:["Verify environment variable is set: ",(0,i.jsx)(n.code,{children:"echo $RETRIEVER"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'"Invalid retriever(s) found"'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Check available retrievers: ",(0,i.jsx)(n.code,{children:"tavily"}),", ",(0,i.jsx)(n.code,{children:"mcp"}),", ",(0,i.jsx)(n.code,{children:"google"}),", ",(0,i.jsx)(n.code,{children:"bing"}),", ",(0,i.jsx)(n.code,{children:"arxiv"}),", etc."]}),"\n",(0,i.jsx)(n.li,{children:"Ensure no typos in retriever names"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'"No MCP server configurations found"'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Ensure ",(0,i.jsx)(n.code,{children:"mcp_configs"})," is a list of dictionaries"]}),"\n",(0,i.jsx)(n.li,{children:"Verify at least one configuration is provided"}),"\n",(0,i.jsx)(n.li,{children:"Check configuration format matches examples"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'"MCP server connection failed"'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Verify server command and arguments"}),"\n",(0,i.jsx)(n.li,{children:"Check environment variables are set correctly"}),"\n",(0,i.jsx)(n.li,{children:"Test the MCP server independently"}),"\n",(0,i.jsx)(n.li,{children:"Ensure required dependencies are installed"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'"No tools available from MCP server"'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Verify the server exposes tools correctly"}),"\n",(0,i.jsx)(n.li,{children:"Check server startup logs for errors"}),"\n",(0,i.jsxs)(n.li,{children:["Try enabling ",(0,i.jsx)(n.code,{children:"MCP_AUTO_TOOL_SELECTION=true"})]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.strong,{children:'"Tool execution failed"'})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Check authentication tokens and API keys"}),"\n",(0,i.jsx)(n.li,{children:"Verify tool arguments are valid"}),"\n",(0,i.jsx)(n.li,{children:"Review server logs for detailed errors"}),"\n",(0,i.jsx)(n.li,{children:"Enable debug logging for more information"}),"\n"]}),"\n",(0,i.jsx)(n.h3,{id:"debug-mode",children:"Debug Mode"}),"\n",(0,i.jsx)(n.p,{children:"Enable detailed logging to diagnose issues:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import logging\nlogging.basicConfig(level=logging.DEBUG)\n\n# Your research code here - will show detailed MCP operations\n"})}),"\n",(0,i.jsx)(n.h3,{id:"testing-your-setup",children:"Testing Your Setup"}),"\n",(0,i.jsx)(n.p,{children:"Quick test to verify MCP configuration:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'import os\nfrom gpt_researcher import GPTResearcher\n\n# Test retriever configuration\nos.environ["RETRIEVER"] = "mcp"\n\n# Test basic configuration\nresearcher = GPTResearcher(\n    query="test query",\n    mcp_configs=[\n        {\n            "name": "test",\n            "command": "echo",\n            "args": ["hello world"]\n        }\n    ]\n)\n\nprint(f"\u2705 RETRIEVER set to: {os.environ.get(\'RETRIEVER\')}")\nprint(f"\u2705 MCP configs loaded: {len(researcher.mcp_configs)}")\n'})}),"\n",(0,i.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Always set the RETRIEVER environment variable"})," - This is required for MCP functionality"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use hybrid strategies"})," (",(0,i.jsx)(n.code,{children:"tavily,mcp"}),") for comprehensive research"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Use descriptive server names"})," for easier debugging"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Store sensitive data in environment variables"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Test MCP servers independently"})," before integration"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Enable verbose mode"})," during development"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Choose appropriate retriever combinations"})," based on your research domain"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.strong,{children:"Let the default settings handle optimization"})," for most use cases"]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsxs)(n.em,{children:["For more examples and advanced use cases, check out the ",(0,i.jsx)(n.a,{href:"https://github.com/assafelovic/gpt-researcher/tree/master/examples",children:"GPT Researcher examples repository"}),"."]})," :-)"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>c,x:()=>a});var s=r(6540);const i={},t=s.createContext(i);function c(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);