"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[3824],{1372:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>d,frontMatter:()=>l,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"gpt-researcher/multi_agents/langgraph","title":"LangGraph","description":"LangGraph is a library for building stateful, multi-actor applications with LLMs.","source":"@site/docs/gpt-researcher/multi_agents/langgraph.md","sourceDirName":"gpt-researcher/multi_agents","slug":"/gpt-researcher/multi_agents/langgraph","permalink":"/docs/gpt-researcher/multi_agents/langgraph","draft":false,"unlisted":false,"editUrl":"https://github.com/assafelovic/gpt-researcher/tree/master/docs/docs/gpt-researcher/multi_agents/langgraph.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"MCP Integration with GPT Researcher","permalink":"/docs/gpt-researcher/retrievers/mcp-configs"},"next":{"title":"Getting Started","permalink":"/docs/gpt-researcher/mcp-server/getting-started"}}');var t=s(4848),i=s(8453);const l={},a="LangGraph",o={},c=[{value:"Use case",id:"use-case",level:2},{value:"The Multi Agent Team",id:"the-multi-agent-team",level:2},{value:"How it works",id:"how-it-works",level:2},{value:"Architecture",id:"architecture",level:3},{value:"Steps",id:"steps",level:3},{value:"How to run",id:"how-to-run",level:2},{value:"Usage",id:"usage",level:2},{value:"Task.json contains the following fields:",id:"taskjson-contains-the-following-fields",level:4},{value:"For example:",id:"for-example",level:4},{value:"To Deploy",id:"to-deploy",level:2},{value:"NextJS Frontend App",id:"nextjs-frontend-app",level:2},{value:"Run the NextJS React App with Docker",id:"run-the-nextjs-react-app-with-docker",level:3},{value:"Run the NextJS React App with NPM",id:"run-the-nextjs-react-app-with-npm",level:3}];function h(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"langgraph",children:"LangGraph"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://python.langchain.com/docs/langgraph",children:"LangGraph"})," is a library for building stateful, multi-actor applications with LLMs.\nThis example uses Langgraph to automate the process of an in depth research on any given topic."]}),"\n",(0,t.jsx)(n.h2,{id:"use-case",children:"Use case"}),"\n",(0,t.jsxs)(n.p,{children:["By using Langgraph, the research process can be significantly improved in depth and quality by leveraging multiple agents with specialized skills.\nInspired by the recent ",(0,t.jsx)(n.a,{href:"https://arxiv.org/abs/2402.14207",children:"STORM"})," paper, this example showcases how a team of AI agents can work together to conduct research on a given topic, from planning to publication."]}),"\n",(0,t.jsx)(n.p,{children:"An average run generates a 5-6 page research report in multiple formats such as PDF, Docx and Markdown."}),"\n",(0,t.jsx)(n.p,{children:"Please note: This example uses the OpenAI API only for optimized performance."}),"\n",(0,t.jsx)(n.h2,{id:"the-multi-agent-team",children:"The Multi Agent Team"}),"\n",(0,t.jsx)(n.p,{children:"The research team is made up of 7 AI agents:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Human"})," - The human in the loop that oversees the process and provides feedback to the agents."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chief Editor"}),' - Oversees the research process and manages the team. This is the "master" agent that coordinates the other agents using Langgraph.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Researcher"})," (gpt-researcher) - A specialized autonomous agent that conducts in depth research on a given topic."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Editor"})," - Responsible for planning the research outline and structure."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Reviewer"})," - Validates the correctness of the research results given a set of criteria."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Revisor"})," - Revises the research results based on the feedback from the reviewer."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Writer"})," - Responsible for compiling and writing the final report."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Publisher"})," - Responsible for publishing the final report in various formats."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"how-it-works",children:"How it works"}),"\n",(0,t.jsx)(n.p,{children:"Generally, the process is based on the following stages:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Planning stage"}),"\n",(0,t.jsx)(n.li,{children:"Data collection and analysis"}),"\n",(0,t.jsx)(n.li,{children:"Review and revision"}),"\n",(0,t.jsx)(n.li,{children:"Writing and submission"}),"\n",(0,t.jsx)(n.li,{children:"Publication"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"architecture",children:"Architecture"}),"\n",(0,t.jsx)("div",{align:"center",children:(0,t.jsx)("img",{align:"center",height:"600",src:"https://cowriter-images.s3.amazonaws.com/multi-agents-gptr.png"})}),"\n",(0,t.jsx)("br",{clear:"all"}),"\n",(0,t.jsx)(n.h3,{id:"steps",children:"Steps"}),"\n",(0,t.jsx)(n.p,{children:"More specifically (as seen in the architecture diagram) the process is as follows:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Browser (gpt-researcher) - Browses the internet for initial research based on the given research task."}),"\n",(0,t.jsx)(n.li,{children:"Editor - Plans the report outline and structure based on the initial research."}),"\n",(0,t.jsxs)(n.li,{children:["For each outline topic (in parallel):","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Researcher (gpt-researcher) - Runs an in depth research on the subtopics and writes a draft."}),"\n",(0,t.jsx)(n.li,{children:"Reviewer - Validates the correctness of the draft given a set of criteria and provides feedback."}),"\n",(0,t.jsx)(n.li,{children:"Revisor - Revises the draft until it is satisfactory based on the reviewer feedback."}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:"Writer - Compiles and writes the final report including an introduction, conclusion and references section from the given research findings."}),"\n",(0,t.jsx)(n.li,{children:"Publisher - Publishes the final report to multi formats such as PDF, Docx, Markdown, etc."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"how-to-run",children:"How to run"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Install required packages:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip install -r requirements.txt\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Update env variables","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"export OPENAI_API_KEY={Your OpenAI API Key here}\nexport TAVILY_API_KEY={Your Tavily API Key here}\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["Run the application:","\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python main.py\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"usage",children:"Usage"}),"\n",(0,t.jsxs)(n.p,{children:["To change the research query and customize the report, edit the ",(0,t.jsx)(n.code,{children:"task.json"})," file in the main directory."]}),"\n",(0,t.jsx)(n.h4,{id:"taskjson-contains-the-following-fields",children:"Task.json contains the following fields:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"query"})," - The research query or task."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"model"})," - The OpenAI LLM to use for the agents."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"max_sections"})," - The maximum number of sections in the report. Each section is a subtopic of the research query."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"include_human_feedback"})," - If true, the user can provide feedback to the agents. If false, the agents will work autonomously."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"publish_formats"})," - The formats to publish the report in. The reports will be written in the ",(0,t.jsx)(n.code,{children:"output"})," directory."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"source"})," - The location from which to conduct the research. Options: ",(0,t.jsx)(n.code,{children:"web"})," or ",(0,t.jsx)(n.code,{children:"local"}),". For local, please add ",(0,t.jsx)(n.code,{children:"DOC_PATH"})," env var."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"follow_guidelines"})," - If true, the research report will follow the guidelines below. It will take longer to complete. If false, the report will be generated faster but may not follow the guidelines."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"guidelines"})," - A list of guidelines that the report must follow."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"verbose"})," - If true, the application will print detailed logs to the console."]}),"\n"]}),"\n",(0,t.jsx)(n.h4,{id:"for-example",children:"For example:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "query": "Is AI in a hype cycle?",\n  "model": "gpt-4o",\n  "max_sections": 3, \n  "publish_formats": { \n    "markdown": true,\n    "pdf": true,\n    "docx": true\n  },\n  "include_human_feedback": false,\n  "source": "web",\n  "follow_guidelines": true,\n  "guidelines": [\n    "The report MUST fully answer the original question",\n    "The report MUST be written in apa format",\n    "The report MUST be written in english"\n  ],\n  "verbose": true\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"to-deploy",children:"To Deploy"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-shell",children:"pip install langgraph-cli\nlanggraph up\n"})}),"\n",(0,t.jsxs)(n.p,{children:["From there, see documentation ",(0,t.jsx)(n.a,{href:"https://github.com/langchain-ai/langgraph-example",children:"here"})," on how to use the streaming and async endpoints, as well as the playground."]}),"\n",(0,t.jsx)(n.h2,{id:"nextjs-frontend-app",children:"NextJS Frontend App"}),"\n",(0,t.jsxs)(n.p,{children:["The React app (located in ",(0,t.jsx)(n.code,{children:"frontend"})," directory) is our Frontend 2.0 which we hope will enable us to display the robustness of the backend on the frontend, as well."]}),"\n",(0,t.jsx)(n.p,{children:"It comes with loads of added features, such as:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"a drag-n-drop user interface for uploading and deleting files to be used as local documents by GPTResearcher."}),"\n",(0,t.jsx)(n.li,{children:"a GUI for setting your GPTR environment variables."}),"\n",(0,t.jsx)(n.li,{children:"the ability to trigger the multi_agents flow via the Backend Module or Langgraph Cloud Host (currently in closed beta)."}),"\n",(0,t.jsx)(n.li,{children:"stability fixes"}),"\n",(0,t.jsx)(n.li,{children:"and more coming soon!"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"run-the-nextjs-react-app-with-docker",children:"Run the NextJS React App with Docker"}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 1"})," - ",(0,t.jsx)(n.a,{href:"https://docs.gptr.dev/docs/gpt-researcher/getting-started/getting-started-with-docker",children:"Install Docker"})]}),"\n"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 2"})," - Clone the '.env.example' file, add your API Keys to the cloned file and save the file as '.env'"]}),"\n"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 3"})," - Within the docker-compose file comment out services that you don't want to run with Docker."]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"$ docker-compose up --build\n"})}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Step 4"})," - By default, if you haven't uncommented anything in your docker-compose file, this flow will start 2 processes:"]}),"\n"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"the Python server running on localhost:8000"}),"\n",(0,t.jsx)(n.li,{children:"the React app running on localhost:3000"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Visit localhost:3000 on any browser and enjoy researching!"}),"\n",(0,t.jsx)(n.h3,{id:"run-the-nextjs-react-app-with-npm",children:"Run the NextJS React App with NPM"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd frontend/nextjs\nnvm install 18.17.0\nnvm use v18.17.0\nnpm install --legacy-peer-deps\nnpm run dev\n"})})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(h,{...e})}):h(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>a});var r=s(6540);const t={},i=r.createContext(t);function l(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);