"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8907],{3227:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>o,contentTitle:()=>c,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"gpt-researcher/gptr/deep_research","title":"Deep Research \u2728 NEW \u2728","description":"With the latest \\"Deep Research\\" trend in the AI community, we\'re excited to implement our own Open source deep research capability! Introducing GPT Researcher\'s Deep Research - an advanced recursive research system that explores topics with unprecedented depth and breadth.","source":"@site/docs/gpt-researcher/gptr/deep_research.md","sourceDirName":"gpt-researcher/gptr","slug":"/gpt-researcher/gptr/deep_research","permalink":"/docs/gpt-researcher/gptr/deep_research","draft":false,"unlisted":false,"editUrl":"https://github.com/assafelovic/gpt-researcher/tree/master/docs/docs/gpt-researcher/gptr/deep_research.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Agent Example","permalink":"/docs/gpt-researcher/gptr/example"},"next":{"title":"Configuration","permalink":"/docs/gpt-researcher/gptr/config"}}');var t=n(4848),i=n(8453);const a={},c="Deep Research \u2728 NEW \u2728",o={},l=[{value:"How It Works",id:"how-it-works",level:2},{value:"Process Flow",id:"process-flow",level:2},{value:"Quick Start",id:"quick-start",level:2},{value:"Configuration",id:"configuration",level:2},{value:"Progress Tracking",id:"progress-tracking",level:2},{value:"Error Handling",id:"error-handling",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Limitations",id:"limitations",level:2}];function d(e){const r={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(r.header,{children:(0,t.jsx)(r.h1,{id:"deep-research--new-",children:"Deep Research \u2728 NEW \u2728"})}),"\n",(0,t.jsx)(r.p,{children:"With the latest \"Deep Research\" trend in the AI community, we're excited to implement our own Open source deep research capability! Introducing GPT Researcher's Deep Research - an advanced recursive research system that explores topics with unprecedented depth and breadth."}),"\n",(0,t.jsxs)(r.p,{children:["Each deep research takes around 5 minutes to complete and costs around $0.4 (using ",(0,t.jsx)(r.code,{children:"o3-mini"})," on ",(0,t.jsx)(r.code,{children:'"high" '}),"reasoning effort)"]}),"\n",(0,t.jsx)(r.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,t.jsx)(r.p,{children:"Deep Research employs a fascinating tree-like exploration pattern:"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Breadth"}),": At each level, it generates multiple search queries to explore different aspects of your topic"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Depth"}),": For each branch, it recursively dives deeper, following leads and uncovering connections"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Concurrent Processing"}),": Utilizes async/await patterns to run multiple research paths simultaneously"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Smart Context Management"}),": Automatically aggregates and synthesizes findings across all branches"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Progress Tracking"}),": Real-time updates on research progress across both breadth and depth dimensions"]}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"Think of it as deploying a team of AI researchers, each following their own research path while collaborating to build a comprehensive understanding of your topic."}),"\n",(0,t.jsx)(r.h2,{id:"process-flow",children:"Process Flow"}),"\n",(0,t.jsx)("img",{src:"https://github.com/user-attachments/assets/eba2d94b-bef3-4f8d-bbc0-f15bd0a40968",alt:"Logo",width:"568"}),"\n",(0,t.jsx)("br",{}),"\n",(0,t.jsx)(r.h2,{id:"quick-start",children:"Quick Start"}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:'from gpt_researcher import GPTResearcher\nfrom gpt_researcher.utils.enum import ReportType, Tone\nimport asyncio\n\nasync def main():\n    # Initialize researcher with deep research type\n    researcher = GPTResearcher(\n        query="What are the latest developments in quantum computing?",\n        report_type="deep",  # This triggers deep research modd\n    )\n\n    # Run research\n    research_data = await researcher.conduct_research()\n\n    # Generate report\n    report = await researcher.write_report()\n    print(report)\n\nif __name__ == "__main__":\n    asyncio.run(main())\n'})}),"\n",(0,t.jsx)(r.h2,{id:"configuration",children:"Configuration"}),"\n",(0,t.jsx)(r.p,{children:"Deep Research behavior can be customized through several parameters:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"deep_research_breadth"}),": Number of parallel research paths at each level (default: 4)"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"deep_research_depth"}),": How many levels deep to explore (default: 2)"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"deep_research_concurrency"}),": Maximum number of concurrent research operations (default: 4)"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.code,{children:"total_words"}),": Total words in the generated report (recommended: 2000)"]}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"You can configure these parameters in multiple ways:"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Environment Variables"}),":"]}),"\n"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-bash",children:"export DEEP_RESEARCH_BREADTH=4\nexport DEEP_RESEARCH_DEPTH=2\nexport DEEP_RESEARCH_CONCURRENCY=4\nexport TOTAL_WORDS=2500\n"})}),"\n",(0,t.jsxs)(r.ol,{start:"2",children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Config File"}),":"]}),"\n"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-yaml",children:"deep_research_breadth: 4\ndeep_research_depth: 2\ndeep_research_concurrency: 4\ntotal_words: 2500\n"})}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:'researcher = GPTResearcher(\n    query="your query",\n    report_type="deep",\n    config_path="path/to/config.yaml"  # Configure deep research parameters here\n)\n'})}),"\n",(0,t.jsx)(r.h2,{id:"progress-tracking",children:"Progress Tracking"}),"\n",(0,t.jsxs)(r.p,{children:["The ",(0,t.jsx)(r.code,{children:"on_progress"})," callback provides real-time insights into the research process:"]}),"\n",(0,t.jsx)(r.pre,{children:(0,t.jsx)(r.code,{className:"language-python",children:"class ResearchProgress:\n    current_depth: int       # Current depth level\n    total_depth: int         # Maximum depth to explore\n    current_breadth: int     # Current number of parallel paths\n    total_breadth: int       # Maximum breadth at each level\n    current_query: str       # Currently processing query\n    completed_queries: int   # Number of completed queries\n    total_queries: int       # Total queries to process\n"})}),"\n",(0,t.jsx)(r.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,t.jsx)(r.p,{children:"The deep research workflow is designed to be resilient:"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"Failed queries are automatically skipped"}),"\n",(0,t.jsx)(r.li,{children:"Research continues even if some branches fail"}),"\n",(0,t.jsx)(r.li,{children:"Progress tracking helps identify any issues"}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,t.jsxs)(r.ol,{children:["\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Start Broad"}),": Begin with a general query and let the system explore specifics"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Monitor Progress"}),": Use the progress callback to understand the research flow"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Adjust Parameters"}),": Tune breadth and depth based on your needs:","\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsx)(r.li,{children:"More breadth = wider coverage"}),"\n",(0,t.jsx)(r.li,{children:"More depth = deeper insights"}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(r.li,{children:[(0,t.jsx)(r.strong,{children:"Resource Management"}),": Consider concurrency limits based on your system capabilities"]}),"\n"]}),"\n",(0,t.jsx)(r.h2,{id:"limitations",children:"Limitations"}),"\n",(0,t.jsxs)(r.ul,{children:["\n",(0,t.jsxs)(r.li,{children:["Usage of reasoning LLM models such as ",(0,t.jsx)(r.code,{children:"o3-mini"})]}),"\n",(0,t.jsx)(r.li,{children:"Deep research may take longer than standard research"}),"\n",(0,t.jsx)(r.li,{children:"Higher API usage and costs due to multiple concurrent queries"}),"\n",(0,t.jsx)(r.li,{children:"May require more system resources for parallel processing"}),"\n"]}),"\n",(0,t.jsx)(r.p,{children:"Happy researching! \ud83c\udf89"})]})}function h(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,t.jsx)(r,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>a,x:()=>c});var s=n(6540);const t={},i=s.createContext(t);function a(e){const r=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function c(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(i.Provider,{value:r},e.children)}}}]);