"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[8907],{4609:(e,r,t)=>{t.r(r),t.d(r,{contentTitle:()=>s,default:()=>u,frontMatter:()=>i,metadata:()=>o,toc:()=>l});var a=t(8168),n=(t(6540),t(5680));const i={},s="Deep Research \u2728 NEW \u2728",o={unversionedId:"gpt-researcher/gptr/deep_research",id:"gpt-researcher/gptr/deep_research",isDocsHomePage:!1,title:"Deep Research \u2728 NEW \u2728",description:"With the latest \"Deep Research\" trend in the AI community, we're excited to implement our own Open source deep research capability! Introducing GPT Researcher's Deep Research - an advanced recursive research system that explores topics with unprecedented depth and breadth.",source:"@site/docs/gpt-researcher/gptr/deep_research.md",sourceDirName:"gpt-researcher/gptr",slug:"/gpt-researcher/gptr/deep_research",permalink:"/docs/gpt-researcher/gptr/deep_research",editUrl:"https://github.com/assafelovic/gpt-researcher/tree/master/docs/docs/gpt-researcher/gptr/deep_research.md",tags:[],version:"current",frontMatter:{},sidebar:"docsSidebar",previous:{title:"Agent Example",permalink:"/docs/gpt-researcher/gptr/example"},next:{title:"Configuration",permalink:"/docs/gpt-researcher/gptr/config"}},l=[{value:"How It Works",id:"how-it-works",children:[],level:2},{value:"Process Flow",id:"process-flow",children:[],level:2},{value:"Quick Start",id:"quick-start",children:[],level:2},{value:"Configuration",id:"configuration",children:[],level:2},{value:"Progress Tracking",id:"progress-tracking",children:[],level:2},{value:"Error Handling",id:"error-handling",children:[],level:2},{value:"Best Practices",id:"best-practices",children:[],level:2},{value:"Limitations",id:"limitations",children:[],level:2}],c={toc:l},p="wrapper";function u(e){let{components:r,...t}=e;return(0,n.yg)(p,(0,a.A)({},c,t,{components:r,mdxType:"MDXLayout"}),(0,n.yg)("h1",{id:"deep-research--new-"},"Deep Research \u2728 NEW \u2728"),(0,n.yg)("p",null,"With the latest \"Deep Research\" trend in the AI community, we're excited to implement our own Open source deep research capability! Introducing GPT Researcher's Deep Research - an advanced recursive research system that explores topics with unprecedented depth and breadth."),(0,n.yg)("h2",{id:"how-it-works"},"How It Works"),(0,n.yg)("p",null,"Deep Research employs a fascinating tree-like exploration pattern:"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Breadth"),": At each level, it generates multiple search queries to explore different aspects of your topic"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Depth"),": For each branch, it recursively dives deeper, following leads and uncovering connections"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Concurrent Processing"),": Utilizes async/await patterns to run multiple research paths simultaneously"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Smart Context Management"),": Automatically aggregates and synthesizes findings across all branches"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Progress Tracking"),": Real-time updates on research progress across both breadth and depth dimensions")),(0,n.yg)("p",null,"Think of it as deploying a team of AI researchers, each following their own research path while collaborating to build a comprehensive understanding of your topic."),(0,n.yg)("h2",{id:"process-flow"},"Process Flow"),(0,n.yg)("img",{src:"https://github.com/user-attachments/assets/eba2d94b-bef3-4f8d-bbc0-f15bd0a40968",alt:"Logo",width:"568"}),(0,n.yg)("br",null),(0,n.yg)("h2",{id:"quick-start"},"Quick Start"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'from gpt_researcher import GPTResearcher\nfrom gpt_researcher.utils.enum import ReportType, Tone\nimport asyncio\n\nasync def main():\n    # Initialize researcher with deep research type\n    researcher = GPTResearcher(\n        query="What are the latest developments in quantum computing?",\n        report_type="deep",  # This triggers deep research modd\n    )\n    \n    # Run research\n    research_data = await researcher.conduct_research()\n    \n    # Generate report\n    report = await researcher.write_report()\n    print(report)\n\nif __name__ == "__main__":\n    asyncio.run(main())\n')),(0,n.yg)("h2",{id:"configuration"},"Configuration"),(0,n.yg)("p",null,"Deep Research behavior can be customized through several parameters:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"deep_research_breadth"),": Number of parallel research paths at each level (default: 4)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"deep_research_depth"),": How many levels deep to explore (default: 2)"),(0,n.yg)("li",{parentName:"ul"},(0,n.yg)("inlineCode",{parentName:"li"},"deep_research_concurrency"),": Maximum number of concurrent research operations (default: 2)")),(0,n.yg)("p",null,"You can configure these in your config file, pass as environment variables or pass them directly:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},'researcher = GPTResearcher(\n    query="your query",\n    report_type="deep",\n    config_path="path/to/config.yaml"  # Configure deep research parameters here\n)\n')),(0,n.yg)("h2",{id:"progress-tracking"},"Progress Tracking"),(0,n.yg)("p",null,"The ",(0,n.yg)("inlineCode",{parentName:"p"},"on_progress")," callback provides real-time insights into the research process:"),(0,n.yg)("pre",null,(0,n.yg)("code",{parentName:"pre",className:"language-python"},"class ResearchProgress:\n    current_depth: int       # Current depth level\n    total_depth: int         # Maximum depth to explore\n    current_breadth: int     # Current number of parallel paths\n    total_breadth: int       # Maximum breadth at each level\n    current_query: str       # Currently processing query\n    completed_queries: int   # Number of completed queries\n    total_queries: int       # Total queries to process\n")),(0,n.yg)("h2",{id:"error-handling"},"Error Handling"),(0,n.yg)("p",null,"The deep research workflow is designed to be resilient:"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Failed queries are automatically skipped"),(0,n.yg)("li",{parentName:"ul"},"Research continues even if some branches fail"),(0,n.yg)("li",{parentName:"ul"},"Progress tracking helps identify any issues")),(0,n.yg)("h2",{id:"best-practices"},"Best Practices"),(0,n.yg)("ol",null,(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Start Broad"),": Begin with a general query and let the system explore specifics"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Monitor Progress"),": Use the progress callback to understand the research flow"),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Adjust Parameters"),": Tune breadth and depth based on your needs:",(0,n.yg)("ul",{parentName:"li"},(0,n.yg)("li",{parentName:"ul"},"More breadth = wider coverage"),(0,n.yg)("li",{parentName:"ul"},"More depth = deeper insights"))),(0,n.yg)("li",{parentName:"ol"},(0,n.yg)("strong",{parentName:"li"},"Resource Management"),": Consider concurrency limits based on your system capabilities")),(0,n.yg)("h2",{id:"limitations"},"Limitations"),(0,n.yg)("ul",null,(0,n.yg)("li",{parentName:"ul"},"Usage of reasoning LLM models such as ",(0,n.yg)("inlineCode",{parentName:"li"},"o3-mini")),(0,n.yg)("li",{parentName:"ul"},"Deep research may take longer than standard research"),(0,n.yg)("li",{parentName:"ul"},"Higher API usage and costs due to multiple concurrent queries"),(0,n.yg)("li",{parentName:"ul"},"May require more system resources for parallel processing")),(0,n.yg)("p",null,"Happy researching! \ud83c\udf89"))}u.isMDXComponent=!0},5680:(e,r,t)=>{t.d(r,{xA:()=>p,yg:()=>h});var a=t(6540);function n(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function i(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);r&&(a=a.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,a)}return t}function s(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?i(Object(t),!0).forEach((function(r){n(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function o(e,r){if(null==e)return{};var t,a,n=function(e,r){if(null==e)return{};var t,a,n={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],r.indexOf(t)>=0||(n[t]=e[t]);return n}(e,r);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(n[t]=e[t])}return n}var l=a.createContext({}),c=function(e){var r=a.useContext(l),t=r;return e&&(t="function"==typeof e?e(r):s(s({},r),e)),t},p=function(e){var r=c(e.components);return a.createElement(l.Provider,{value:r},e.children)},u="mdxType",g={inlineCode:"code",wrapper:function(e){var r=e.children;return a.createElement(a.Fragment,{},r)}},d=a.forwardRef((function(e,r){var t=e.components,n=e.mdxType,i=e.originalType,l=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),u=c(t),d=n,h=u["".concat(l,".").concat(d)]||u[d]||g[d]||i;return t?a.createElement(h,s(s({ref:r},p),{},{components:t})):a.createElement(h,s({ref:r},p))}));function h(e,r){var t=arguments,n=r&&r.mdxType;if("string"==typeof e||n){var i=t.length,s=new Array(i);s[0]=d;var o={};for(var l in r)hasOwnProperty.call(r,l)&&(o[l]=r[l]);o.originalType=e,o[u]="string"==typeof e?e:n,s[1]=o;for(var c=2;c<i;c++)s[c]=t[c];return a.createElement.apply(null,s)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"}}]);