"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[6154],{4637:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"gpt-researcher/mcp-server/advanced-usage","title":"Advanced Usage","description":"This guide covers advanced usage scenarios and configurations for the GPT Researcher MCP Server.","source":"@site/docs/gpt-researcher/mcp-server/advanced-usage.md","sourceDirName":"gpt-researcher/mcp-server","slug":"/gpt-researcher/mcp-server/advanced-usage","permalink":"/docs/gpt-researcher/mcp-server/advanced-usage","draft":false,"unlisted":false,"editUrl":"https://github.com/assafelovic/gpt-researcher/tree/master/docs/docs/gpt-researcher/mcp-server/advanced-usage.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2},"sidebar":"docsSidebar","previous":{"title":"Getting Started","permalink":"/docs/gpt-researcher/mcp-server/getting-started"},"next":{"title":"Claude Desktop Integration","permalink":"/docs/gpt-researcher/mcp-server/claude-integration"}}');var t=r(4848),a=r(8453);const s={sidebar_position:2},o="Advanced Usage",l={},c=[{value:"Custom Configuration",id:"custom-configuration",level:2},{value:"Environment Variables",id:"environment-variables",level:3},{value:"Server Configuration File",id:"server-configuration-file",level:3},{value:"Integrating with Claude",id:"integrating-with-claude",level:2},{value:"Advanced Tool Usage",id:"advanced-tool-usage",level:2},{value:"Conducting Deep Research",id:"conducting-deep-research",level:3},{value:"Customizing Report Generation",id:"customizing-report-generation",level:3},{value:"Securing Your MCP Server",id:"securing-your-mcp-server",level:2},{value:"Deploying with Docker",id:"deploying-with-docker",level:2},{value:"Monitoring and Logging",id:"monitoring-and-logging",level:2},{value:"Extending Functionality",id:"extending-functionality",level:2},{value:"Troubleshooting Advanced Issues",id:"troubleshooting-advanced-issues",level:2},{value:"Handling Rate Limits",id:"handling-rate-limits",level:3},{value:"Memory Management",id:"memory-management",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"advanced-usage",children:"Advanced Usage"})}),"\n",(0,t.jsx)(n.p,{children:"This guide covers advanced usage scenarios and configurations for the GPT Researcher MCP Server."}),"\n",(0,t.jsx)(n.h2,{id:"custom-configuration",children:"Custom Configuration"}),"\n",(0,t.jsx)(n.p,{children:"You can customize the MCP server behavior by modifying various configuration parameters:"}),"\n",(0,t.jsx)(n.h3,{id:"environment-variables",children:"Environment Variables"}),"\n",(0,t.jsxs)(n.p,{children:["Create a ",(0,t.jsx)(n.code,{children:".env"})," file with additional configuration options:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Required API keys\nOPENAI_API_KEY=your_openai_api_key\nTAVILY_API_KEY=your_tavily_api_key\n\n# Optional configurations assuming using OpenAI\nSTRATEGIC_LLM=openai:gpt-4o-mini # Change default to faster reasoning model\nMAX_ITERATIONS=2 # Make the research faster by reducing iterations\nSCRAPER=tavily_extract # For production use, using hosted scraping methods (assuming you use tavily)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"server-configuration-file",children:"Server Configuration File"}),"\n",(0,t.jsxs)(n.p,{children:["You can create a ",(0,t.jsx)(n.code,{children:"config.json"})," file to customize server behavior:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "host": "0.0.0.0",\n  "port": 8000,\n  "debug": false,\n  "timeout": 300,\n  "max_concurrent_requests": 10\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"integrating-with-claude",children:"Integrating with Claude"}),"\n",(0,t.jsx)(n.p,{children:"To integrate with Claude effectively:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Make sure your Claude model has MCP capabilities enabled"}),"\n",(0,t.jsx)(n.li,{children:"Point Claude to the MCP server endpoint"}),"\n",(0,t.jsx)(n.li,{children:"Use the appropriate prompts to guide Claude in using the research tools"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Example configuration for Claude:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-json",children:'{\n  "tools": [\n    {\n      "name": "gptr-researcher",\n      "endpoint": "http://localhost:8000/mcp"\n    }\n  ]\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"advanced-tool-usage",children:"Advanced Tool Usage"}),"\n",(0,t.jsx)(n.h3,{id:"conducting-deep-research",children:"Conducting Deep Research"}),"\n",(0,t.jsx)(n.p,{children:"For deeper research capabilities:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'Use the conduct_research tool with these advanced parameters:\n{\n  "query": "quantum computing advancements 2024",\n  "depth": "deep",\n  "focus_areas": ["hardware", "algorithms", "applications"],\n  "timeline": "last 1 year"\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"customizing-report-generation",children:"Customizing Report Generation"}),"\n",(0,t.jsx)(n.p,{children:"The write_report tool accepts several customization options:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'Use the write_report tool with:\n{\n  "style": "academic",\n  "format": "markdown",\n  "include_images": true,\n  "citation_style": "APA",\n  "executive_summary": true\n}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"securing-your-mcp-server",children:"Securing Your MCP Server"}),"\n",(0,t.jsx)(n.p,{children:"To secure your MCP server deployment:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Add API key authentication:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Add to server.py\n@app.middleware("http")\nasync def verify_api_key(request, call_next):\n    api_key = request.headers.get("X-API-Key")\n    if api_key != os.getenv("MCP_API_KEY"):\n        return JSONResponse(status_code=401, content={"error": "Invalid API key"})\n    return await call_next(request)\n'})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Enable HTTPS:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Run with HTTPS\nuvicorn server:app --host 0.0.0.0 --port 8000 --ssl-keyfile=./key.pem --ssl-certfile=./cert.pem\n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Set up rate limiting:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# Add rate limiting\nfrom fastapi import Depends, HTTPException\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\n\nlimiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\n@app.post("/mcp")\n@limiter.limit("10/minute")\nasync def mcp_endpoint(request: Request, payload: dict):\n    # Endpoint code\n'})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"deploying-with-docker",children:"Deploying with Docker"}),"\n",(0,t.jsx)(n.p,{children:"For easy deployment with Docker:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Create a Dockerfile:"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-dockerfile",children:'FROM python:3.10-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD ["python", "server.py"]\n'})}),"\n",(0,t.jsxs)(n.ol,{start:"2",children:["\n",(0,t.jsx)(n.li,{children:"Build and run the Docker container:"}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"docker build -t gpt-researcher-mcp .\ndocker run -p 8000:8000 -e OPENAI_API_KEY=your_key -e TAVILY_API_KEY=your_key gpt-researcher-mcp\n"})}),"\n",(0,t.jsx)(n.h2,{id:"monitoring-and-logging",children:"Monitoring and Logging"}),"\n",(0,t.jsx)(n.p,{children:"Enable detailed logging to monitor server activity:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format=\'%(asctime)s - %(name)s - %(levelname)s - %(message)s\',\n    handlers=[\n        logging.FileHandler("mcp_server.log"),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger("mcp_server")\n'})}),"\n",(0,t.jsx)(n.h2,{id:"extending-functionality",children:"Extending Functionality"}),"\n",(0,t.jsx)(n.p,{children:"You can extend the MCP server with additional capabilities:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Add new research tools"}),"\n",(0,t.jsx)(n.li,{children:"Implement custom report formats"}),"\n",(0,t.jsx)(n.li,{children:"Integrate with additional data sources"}),"\n",(0,t.jsx)(n.li,{children:"Add specialized research agents"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"For example, to add a new tool:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'@app.tool("analyze_sentiment")\nasync def analyze_sentiment(query: str):\n    """Analyze the sentiment of research results."""\n    # Implementation\n    return {"sentiment": "positive", "confidence": 0.87}\n'})}),"\n",(0,t.jsx)(n.h2,{id:"troubleshooting-advanced-issues",children:"Troubleshooting Advanced Issues"}),"\n",(0,t.jsx)(n.h3,{id:"handling-rate-limits",children:"Handling Rate Limits"}),"\n",(0,t.jsx)(n.p,{children:"If you encounter rate limits with external APIs:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import time\nfrom tenacity import retry, wait_exponential, stop_after_attempt\n\n@retry(wait=wait_exponential(multiplier=1, min=4, max=10), stop=stop_after_attempt(5))\ndef search_with_retry(query):\n    try:\n        return search_engine.search(query)\n    except RateLimitError:\n        time.sleep(5)\n        raise\n"})}),"\n",(0,t.jsx)(n.h3,{id:"memory-management",children:"Memory Management"}),"\n",(0,t.jsx)(n.p,{children:"For handling large research tasks:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import gc\n\ndef clean_memory():\n    """Force garbage collection to free memory"""\n    gc.collect()\n'})}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Explore ",(0,t.jsx)(n.a,{href:"../frontend/introduction",children:"integrating with your own applications"})]}),"\n",(0,t.jsxs)(n.li,{children:["Learn about ",(0,t.jsx)(n.a,{href:"../multi_agents/langgraph",children:"creating custom agents"})," to enhance research capabilities"]}),"\n",(0,t.jsxs)(n.li,{children:["Contribute to the ",(0,t.jsx)(n.a,{href:"../../contribute",children:"GPT Researcher project"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:":-)"})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>o});var i=r(6540);const t={},a=i.createContext(t);function s(e){const n=i.useContext(a);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);