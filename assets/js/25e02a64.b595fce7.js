"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[2082],{3248:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>r,contentTitle:()=>i,default:()=>d,frontMatter:()=>s,metadata:()=>l,toc:()=>h});const l=JSON.parse('{"id":"gpt-researcher/llms/running-with-ollama","title":"Running with Ollama","description":"Ollama is a platform that allows you to deploy and manage custom language models. This guide will walk you through deploying a custom language model on Ollama.","source":"@site/docs/gpt-researcher/llms/running-with-ollama.md","sourceDirName":"gpt-researcher/llms","slug":"/gpt-researcher/llms/running-with-ollama","permalink":"/docs/gpt-researcher/llms/running-with-ollama","draft":false,"unlisted":false,"editUrl":"https://github.com/assafelovic/gpt-researcher/tree/master/docs/docs/gpt-researcher/llms/running-with-ollama.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Running with Azure","permalink":"/docs/gpt-researcher/llms/running-with-azure"},"next":{"title":"Retrievers","permalink":"/docs/gpt-researcher/search-engines/retrievers"}}');var o=n(4848),a=n(8453);const s={},i="Running with Ollama",r={},h=[{value:"Fetching the Desired LLM Models",id:"fetching-the-desired-llm-models",level:2},{value:"Querying your Custom LLM with GPT-Researcher",id:"querying-your-custom-llm-with-gpt-researcher",level:2},{value:"Deploy Ollama on Elestio",id:"deploy-ollama-on-elestio",level:2},{value:"Run LLM Test Script for GPTR",id:"run-llm-test-script-for-gptr",level:2},{value:"Disable Elestio Authentication or Add Auth Headers",id:"disable-elestio-authentication-or-add-auth-headers",level:4}];function c(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h4:"h4",header:"header",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"running-with-ollama",children:"Running with Ollama"})}),"\n",(0,o.jsx)(t.p,{children:"Ollama is a platform that allows you to deploy and manage custom language models. This guide will walk you through deploying a custom language model on Ollama."}),"\n",(0,o.jsx)(t.p,{children:"Read on to understand how to install a Custom LLM with the Ollama WebUI, and how to query it with GPT-Researcher."}),"\n",(0,o.jsx)(t.h2,{id:"fetching-the-desired-llm-models",children:"Fetching the Desired LLM Models"}),"\n",(0,o.jsxs)(t.p,{children:["After deploying Ollama WebUI, you'll want to enter the ",(0,o.jsx)(t.a,{href:"https://github.com/open-webui/open-webui/tree/main",children:"Open WebUI Admin App"})," & download a custom LLM."]}),"\n",(0,o.jsxs)(t.p,{children:["Choose a model from ",(0,o.jsx)(t.a,{href:"https://ollama.com/library?sort=popular",children:"Ollama's Library of LLM's"})]}),"\n",(0,o.jsx)(t.p,{children:"Paste the model name & size into the Web UI:"}),"\n",(0,o.jsx)("img",{width:"1511",alt:"Screen Shot 2024-08-27 at 23 26 28",src:"https://github.com/user-attachments/assets/32abd048-745c-4232-9f1f-6af265cff250"}),"\n",(0,o.jsxs)(t.p,{children:["For our example, let's choose to download the ",(0,o.jsx)(t.code,{children:"qwen2:1.5b"})," from the chat completion model & ",(0,o.jsx)(t.code,{children:"nomic-embed-text"})," for the embeddings model."]}),"\n",(0,o.jsx)(t.p,{children:"This model now automatically becomes available via your Server's out-of-the-box API - we'll leverage it within our GPT-Researcher .env file in the next step."}),"\n",(0,o.jsx)(t.h2,{id:"querying-your-custom-llm-with-gpt-researcher",children:"Querying your Custom LLM with GPT-Researcher"}),"\n",(0,o.jsx)(t.p,{children:"If you deploy ollama locally, a .env like so, should enable powering GPT-Researcher with Ollama:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:'OPENAI_API_KEY="123"\nOPENAI_API_BASE="http://127.0.0.1:11434/v1"\nOLLAMA_BASE_URL="http://127.0.0.1:11434/"\nFAST_LLM="ollama:qwen2:1.5b"\nSMART_LLM="ollama:qwen2:1.5b"\nSTRATEGIC_LLM="ollama:qwen2:1.5b"\nEMBEDDING_PROVIDER="ollama"\nOLLAMA_EMBEDDING_MODEL="nomic-embed-text"\n'})}),"\n",(0,o.jsxs)(t.p,{children:["Replace ",(0,o.jsx)(t.code,{children:"FAST_LLM"})," & ",(0,o.jsx)(t.code,{children:"SMART_LLM"})," with the model you downloaded from the Elestio Web UI in the previous step."]}),"\n",(0,o.jsx)(t.h2,{id:"deploy-ollama-on-elestio",children:"Deploy Ollama on Elestio"}),"\n",(0,o.jsx)(t.p,{children:"Elestio is a platform that allows you to deploy and manage custom language models. This guide will walk you through deploying a custom language model on Elestio."}),"\n",(0,o.jsxs)(t.p,{children:["You can deploy an ",(0,o.jsx)(t.a,{href:"https://github.com/open-webui/open-webui/tree/main",children:"Open WebUI"})," server with ",(0,o.jsx)(t.a,{href:"https://elest.io/open-source/ollama",children:"Elestio"})]}),"\n",(0,o.jsx)(t.h2,{id:"run-llm-test-script-for-gptr",children:"Run LLM Test Script for GPTR"}),"\n",(0,o.jsxs)(t.p,{children:["You can leverage the global ",(0,o.jsx)(t.code,{children:"test-your-llm"})," function with ",(0,o.jsx)(t.code,{children:"tests/test-your-llm"}),".\nHere are the steps to do so:"]}),"\n",(0,o.jsxs)(t.p,{children:["Step 1: Set the following values in your ",(0,o.jsx)(t.code,{children:".env"}),". Note: replace the base urls with the custom domain that your web app is available on - for example: if the web app is available on ",(0,o.jsx)(t.code,{children:"https://ollama-2d52b-u21899.vm.elestio.app/"})," within the browser, that becomes the value to use in your .env file."]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:'OPENAI_API_KEY="123"\nOPENAI_API_BASE="https://ollama-2d52b-u21899.vm.elestio.app:57987/v1"\nOLLAMA_BASE_URL="https://ollama-2d52b-u21899.vm.elestio.app:57987/"\nFAST_LLM="openai:qwen2.5"\nSMART_LLM="openai:qwen2.5"\nSTRATEGIC_LLM="openai:qwen2.5"\nEMBEDDING_PROVIDER="ollama"\nOLLAMA_EMBEDDING_MODEL="nomic-embed-text"\n'})}),"\n",(0,o.jsx)(t.p,{children:"Note: to verify you're pointing at the correct API URL, you can run something like this in your terminal:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"nslookup ollama-2d52b-u21899.vm.elestio.app\n"})}),"\n",(0,o.jsx)(t.p,{children:"Step 2:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:"cd tests\npython -m test-your-llm\n"})}),"\n",(0,o.jsx)(t.p,{children:"You should get an LLM response, such as:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"Sup! How can I assist you today? Feel free to ask me any questions or let me know if you need help with anything.\n"})}),"\n",(0,o.jsx)(t.h4,{id:"disable-elestio-authentication-or-add-auth-headers",children:"Disable Elestio Authentication or Add Auth Headers"}),"\n",(0,o.jsx)(t.p,{children:"To remove the basic auth you have to follow the below steps:"}),"\n",(0,o.jsx)(t.p,{children:"Go to your service -> Security in your Elestio admin panel."}),"\n",(0,o.jsx)(t.p,{children:"Step 1: Disable the Firewall."}),"\n",(0,o.jsx)(t.p,{children:"Step 2: Edit your Nginx Configuration. You'll want to comment both these both these lines out:"}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{className:"language-bash",children:'auth_basic           "Authentication"; \nauth_basic_user_file /etc/nginx/conf.d/.htpasswd;\n'})}),"\n",(0,o.jsx)(t.p,{children:'Step 2: Click the button "Update & Restart" to apply your nginx changes.'})]})}function d(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>s,x:()=>i});var l=n(6540);const o={},a=l.createContext(o);function s(e){const t=l.useContext(a);return l.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),l.createElement(a.Provider,{value:t},e.children)}}}]);