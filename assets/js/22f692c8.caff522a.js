"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[2363],{1903:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"gpt-researcher/gptr/scraping","title":"Scraping Options","description":"GPT Researcher now offers various methods for web scraping: static scraping with BeautifulSoup, dynamic scraping with Selenium, and High scale scraping with Tavily Extract. This document explains how to switch between these methods and the benefits of each approach.","source":"@site/docs/gpt-researcher/gptr/scraping.md","sourceDirName":"gpt-researcher/gptr","slug":"/gpt-researcher/gptr/scraping","permalink":"/docs/gpt-researcher/gptr/scraping","draft":false,"unlisted":false,"editUrl":"https://github.com/assafelovic/gpt-researcher/tree/master/docs/docs/gpt-researcher/gptr/scraping.md","tags":[],"version":"current","frontMatter":{},"sidebar":"docsSidebar","previous":{"title":"Configuration","permalink":"/docs/gpt-researcher/gptr/config"},"next":{"title":"Querying the Backend","permalink":"/docs/gpt-researcher/gptr/querying-the-backend"}}');var s=r(4848),t=r(8453);const l={},a="Scraping Options",c={},o=[{value:"Configuring Scraping Method",id:"configuring-scraping-method",level:2},{value:"Scraping Methods Explained",id:"scraping-methods-explained",level:2},{value:"BeautifulSoup (Static Scraping)",id:"beautifulsoup-static-scraping",level:3},{value:"Selenium (Browser Scraping)",id:"selenium-browser-scraping",level:3},{value:"NoDriver (Browser Scraping)",id:"nodriver-browser-scraping",level:3},{value:"Tavily Extract (Recommended for Production)",id:"tavily-extract-recommended-for-production",level:3},{value:"FireCrawl (Recommended for Production)",id:"firecrawl-recommended-for-production",level:3},{value:"Additional Setup for Selenium",id:"additional-setup-for-selenium",level:2},{value:"Choosing the Right Method",id:"choosing-the-right-method",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"scraping-options",children:"Scraping Options"})}),"\n",(0,s.jsx)(n.p,{children:"GPT Researcher now offers various methods for web scraping: static scraping with BeautifulSoup, dynamic scraping with Selenium, and High scale scraping with Tavily Extract. This document explains how to switch between these methods and the benefits of each approach."}),"\n",(0,s.jsx)(n.h2,{id:"configuring-scraping-method",children:"Configuring Scraping Method"}),"\n",(0,s.jsxs)(n.p,{children:["You can choose your preferred scraping method by setting the ",(0,s.jsx)(n.code,{children:"SCRAPER"})," environment variable:"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"For BeautifulSoup (static scraping):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'export SCRAPER="bs"\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"For dynamic browser scraping, either with Selenium:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'export SCRAPER="browser"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Or with NoDriver (ZenDriver):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'export SCRAPER="nodriver"\npip install zendriver\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["For ",(0,s.jsx)(n.strong,{children:"production"})," use cases, you can set the Scraper to ",(0,s.jsx)(n.code,{children:"tavily_extract"})," or ",(0,s.jsx)(n.code,{children:"firecrawl"}),". ",(0,s.jsx)(n.a,{href:"https://tavily.com",children:"Tavily"})," allows you to scrape sites at scale without the hassle of setting up proxies, managing cookies, or dealing with CAPTCHAs. Please note that you need to have a Tavily account and ",(0,s.jsx)(n.a,{href:"https://app.tavily.com",children:"API key"})," to use this option. To learn more about Tavily Extract ",(0,s.jsx)(n.a,{href:"https://docs.tavily.com/docs/python-sdk/tavily-extract/getting-started",children:"see here"}),".\nMake sure to first install the pip package ",(0,s.jsx)(n.code,{children:"tavily-python"}),". Then:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:'export SCRAPER="tavily_extract"\n'})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://firecrawl.dev",children:"FireCrawl"})," is also allows you to scrape sites at scale. FireCrawl also provides open source code to self hosted server which provided better scrape quality compared to BeautifulSoup by passing markdown version of the scraped sites to LLMs. You will needs to have FireCrawl account (official service) to get API key or you needs self host URL and API key (if you set for your self host server) to use this option.\nMake sure to install the pip package ",(0,s.jsx)(n.code,{children:"firecrawl-py"}),". Then:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'export SCRAPER="firecrawl"\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Note: If not set, GPT Researcher will default to BeautifulSoup for scraping."}),"\n",(0,s.jsx)(n.h2,{id:"scraping-methods-explained",children:"Scraping Methods Explained"}),"\n",(0,s.jsx)(n.h3,{id:"beautifulsoup-static-scraping",children:"BeautifulSoup (Static Scraping)"}),"\n",(0,s.jsxs)(n.p,{children:["When ",(0,s.jsx)(n.code,{children:'SCRAPER="bs"'}),", GPT Researcher uses BeautifulSoup for static scraping. This method:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Sends a single HTTP request to fetch the page content"}),"\n",(0,s.jsx)(n.li,{children:"Parses the static HTML content"}),"\n",(0,s.jsx)(n.li,{children:"Extracts text and data from the parsed HTML"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Benefits:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Faster and more lightweight"}),"\n",(0,s.jsx)(n.li,{children:"Doesn't require additional setup"}),"\n",(0,s.jsx)(n.li,{children:"Works well for simple, static websites"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Limitations:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Cannot handle dynamic content loaded by JavaScript"}),"\n",(0,s.jsx)(n.li,{children:"May miss content that requires user interaction to display"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"selenium-browser-scraping",children:"Selenium (Browser Scraping)"}),"\n",(0,s.jsxs)(n.p,{children:["When ",(0,s.jsx)(n.code,{children:'SCRAPER="browser"'}),", GPT Researcher uses Selenium for dynamic scraping. This method:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Opens a real browser instance (Chrome by default)"}),"\n",(0,s.jsx)(n.li,{children:"Loads the page and executes JavaScript"}),"\n",(0,s.jsx)(n.li,{children:"Waits for dynamic content to load"}),"\n",(0,s.jsx)(n.li,{children:"Extracts text and data from the fully rendered page"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Benefits:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Can scrape dynamically loaded content"}),"\n",(0,s.jsx)(n.li,{children:"Simulates real user interactions (scrolling, clicking, etc.)"}),"\n",(0,s.jsx)(n.li,{children:"Works well for complex, JavaScript-heavy websites"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Limitations:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Slower than static scraping"}),"\n",(0,s.jsx)(n.li,{children:"Requires more system resources"}),"\n",(0,s.jsx)(n.li,{children:"Requires additional setup (Selenium and WebDriver installation)"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"nodriver-browser-scraping",children:"NoDriver (Browser Scraping)"}),"\n",(0,s.jsx)(n.p,{children:"Alternative to Selenium for potentially better performance."}),"\n",(0,s.jsx)(n.p,{children:"Setup:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install zendriver\n"})}),"\n",(0,s.jsx)(n.h3,{id:"tavily-extract-recommended-for-production",children:"Tavily Extract (Recommended for Production)"}),"\n",(0,s.jsxs)(n.p,{children:["When ",(0,s.jsx)(n.code,{children:'SCRAPER="tavily_extract"'}),", GPT Researcher uses Tavily's Extract API for web scraping. This method:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Uses Tavily's robust infrastructure to handle web scraping at scale"}),"\n",(0,s.jsx)(n.li,{children:"Automatically handles CAPTCHAs, JavaScript rendering, and anti-bot measures"}),"\n",(0,s.jsx)(n.li,{children:"Provides clean, structured content extraction"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Benefits:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Production-ready and highly reliable"}),"\n",(0,s.jsx)(n.li,{children:"No need to manage proxies or handle rate limiting"}),"\n",(0,s.jsx)(n.li,{children:"Excellent success rate on most websites"}),"\n",(0,s.jsx)(n.li,{children:"Handles both static and dynamic content"}),"\n",(0,s.jsx)(n.li,{children:"Built-in content cleaning and formatting"}),"\n",(0,s.jsx)(n.li,{children:"Fast response times through Tavily's distributed infrastructure"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Setup:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Create a Tavily account at ",(0,s.jsx)(n.a,{href:"https://app.tavily.com",children:"app.tavily.com"})]}),"\n",(0,s.jsx)(n.li,{children:"Get your API key from the dashboard"}),"\n",(0,s.jsxs)(n.li,{children:["Install the Tavily Python SDK:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install tavily-python\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Set your Tavily API key:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'export TAVILY_API_KEY="your-api-key"\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Usage Considerations:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Requires a Tavily API key and account"}),"\n",(0,s.jsx)(n.li,{children:"API calls are metered based on your Tavily plan"}),"\n",(0,s.jsx)(n.li,{children:"Best for production environments where reliability is crucial"}),"\n",(0,s.jsx)(n.li,{children:"Ideal for businesses and applications that need consistent scraping results"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"firecrawl-recommended-for-production",children:"FireCrawl (Recommended for Production)"}),"\n",(0,s.jsxs)(n.p,{children:["When ",(0,s.jsx)(n.code,{children:'SCRAPER="firecrawl"'}),", GPT Researcher uses FireCrawl Scrape API for web scraping in markdown format. This method:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Uses FireCrawl's robust infrastructure to handle web scraping at scale"}),"\n",(0,s.jsx)(n.li,{children:"Or uses self-hosted FireCrawl server."}),"\n",(0,s.jsx)(n.li,{children:"Automatically handles CAPTCHAs, JavaScript rendering, and anti-bot measures"}),"\n",(0,s.jsx)(n.li,{children:"Provides clean, structured content extraction in markdown format."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Benefits:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Production-ready and highly reliable"}),"\n",(0,s.jsx)(n.li,{children:"No need to manage proxies or handle rate limiting"}),"\n",(0,s.jsx)(n.li,{children:"Excellent success rate on most websites"}),"\n",(0,s.jsx)(n.li,{children:"Handles both static and dynamic content"}),"\n",(0,s.jsx)(n.li,{children:"Built-in content cleaning and formatting"}),"\n",(0,s.jsx)(n.li,{children:"Fast response times through FireCrawl's distributed infrastructure"}),"\n",(0,s.jsx)(n.li,{children:"Ease of setup with FireCrawl self-hosted"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Setup (official service by FireCrawl):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Create a FireCrawl account at ",(0,s.jsx)(n.a,{href:"https://www.firecrawl.dev/app",children:"firecrawl.dev/app"})]}),"\n",(0,s.jsx)(n.li,{children:"Get your API key from the dashboard"}),"\n",(0,s.jsxs)(n.li,{children:["Install the FireCrawl Python SDK:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install firecrawl-py\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Set your FireCrawl API key:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"export FIRECRAWL_API_KEY=<your-firecrawl-api>\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Setup (with self-hosted server):"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Host your FireCrawl. Read their ",(0,s.jsx)(n.a,{href:"https://docs.firecrawl.dev/contributing/self-host",children:"self-hosted guidelines"})," or ",(0,s.jsx)(n.a,{href:"https://docs.firecrawl.dev/contributing/guide",children:"run locally guidelines"})]}),"\n",(0,s.jsx)(n.li,{children:"Get your server URL and API key (if you set it)."}),"\n",(0,s.jsxs)(n.li,{children:["Install the FireCrawl Python SDK:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"pip install firecrawl-py\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["Set your FireCrawl API key:","\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"export FIRECRAWL_API_KEY=<your-firecrawl-api>\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Note: ",(0,s.jsx)(n.code,{children:"FIRECRAWL_API_KEY"})," can be empty if you not setup authentication for your self host server (",(0,s.jsx)(n.code,{children:'FIRECRAWL_API_KEY=""'}),").\nThere will be some difference between their cloud service and open source service. To understand differences between FireCrawl option read ",(0,s.jsx)(n.a,{href:"https://docs.firecrawl.dev/contributing/open-source-or-cloud",children:"here"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Usage Considerations:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Requires a FireCrawl API key and account or self-hosted server"}),"\n",(0,s.jsx)(n.li,{children:"API calls are metered based on your FireCrawl plan (it can be basically free with self-hosted FireCrawl method)"}),"\n",(0,s.jsx)(n.li,{children:"Best for production environments where reliability is crucial (for their cloud service)"}),"\n",(0,s.jsx)(n.li,{children:"Ideal for businesses and applications that need consistent scraping results"}),"\n",(0,s.jsx)(n.li,{children:"Need robust scraping option for personal use"}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"additional-setup-for-selenium",children:"Additional Setup for Selenium"}),"\n",(0,s.jsx)(n.p,{children:'If you choose to use Selenium (SCRAPER="browser"), you\'ll need to:'}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Install the Selenium package:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{children:"pip install selenium\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Download the appropriate WebDriver for your browser:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["For Chrome: ",(0,s.jsx)(n.a,{href:"https://sites.google.com/a/chromium.org/chromedriver/downloads",children:"ChromeDriver"})]}),"\n",(0,s.jsxs)(n.li,{children:["For Firefox: ",(0,s.jsx)(n.a,{href:"https://github.com/mozilla/geckodriver/releases",children:"GeckoDriver"})]}),"\n",(0,s.jsx)(n.li,{children:"For Safari: Built-in, no download required"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Ensure the WebDriver is in your system's PATH."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"choosing-the-right-method",children:"Choosing the Right Method"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Use BeautifulSoup (static) for:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Simple websites with mostly static content"}),"\n",(0,s.jsx)(n.li,{children:"Scenarios where speed is a priority"}),"\n",(0,s.jsx)(n.li,{children:"When you don't need to interact with the page"}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Use Selenium (dynamic) for:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Websites with content loaded via JavaScript"}),"\n",(0,s.jsx)(n.li,{children:"Sites that require scrolling or clicking to load more content"}),"\n",(0,s.jsx)(n.li,{children:"When you need to simulate user interactions"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"If Selenium fails to start, ensure you have the correct WebDriver installed and it's in your system's PATH."}),"\n",(0,s.jsxs)(n.li,{children:["If you encounter an ",(0,s.jsx)(n.code,{children:"ImportError"})," related to Selenium, make sure you've installed the Selenium package."]}),"\n",(0,s.jsx)(n.li,{children:"If the scraper misses expected content, try switching between static and dynamic scraping to see which works better for your target website."}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"Remember, the choice between static and dynamic scraping can significantly impact the quality and completeness of the data GPT Researcher can gather. Choose the method that best suits your research needs and the websites you're targeting."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>a});var i=r(6540);const s={},t=i.createContext(s);function l(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);