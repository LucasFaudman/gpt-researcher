---
title: MCP Configurations
description: How to configure and use MCP (Model Context Protocol) servers more efficiently with GPT Researcher
---

# Using MCP Configurations in GPT Researcher

The Model Context Protocol (MCP) allows GPT Researcher to connect with a wide variety of data sources and tools through a standardized interface. This guide explains how to use the improved `mcp_configs` parameter for more scalable and maintainable MCP integration.

## MCP Configuration Basics

The `mcp_configs` parameter accepts a list of configuration dictionaries, making it easy to connect to multiple MCP servers in a single research session.

```python
from gpt_researcher import GPTResearcher

researcher = GPTResearcher(
    query="Your research question",
    mcp_configs=[
        {
            "server_command": "python",
            "server_args": ["path/to/your/mcp_server.py"],
            "tool_name": "search"
        }
    ]
)
```

## Configuration Structure

Each MCP configuration dictionary can include the following keys:

| Key | Description | Example |
|-----|-------------|---------|
| `server_name` | Name of the MCP server | `"github"` |
| `server_command` | Command to start the MCP server | `"python"` |
| `server_args` | List of arguments for the server command | `["-m", "my_mcp_server"]` |
| `tool_name` | Name of the MCP tool to invoke | `"search"` |
| `env` | Dictionary of environment variables | `{"API_KEY": "your_key"}` |
| `connection_type` | Type of connection (optional, auto-detected from URL) | `"websocket"` |
| `connection_url` | URL for WebSocket or HTTP connection | `"wss://example.com/mcp"` |
| `connection_token` | Authentication token | `"your_auth_token"` |

## Understanding Tool Arguments in MCP

In accordance with MCP protocol design principles, tool arguments are **dynamically generated** by the LLM based on the research query context. This means:

1. You don't need to specify static tool arguments in your configuration
2. The LLM intelligently formulates appropriate arguments for each MCP tool call
3. Arguments are contextually relevant to the current research topic
4. Each tool invocation gets fresh, query-specific parameters

This dynamic approach allows the AI to better adapt to different research needs and make more effective use of available MCP tools.

## Examples

### Basic Local MCP Server

```python
from gpt_researcher import GPTResearcher

researcher = GPTResearcher(
    query="How does quantum computing work?",
    mcp_configs=[
        {
            "server_command": "python",
            "server_args": ["path/to/quantum_mcp_server.py"],
            "tool_name": "search"
        }
    ]
)

context = await researcher.conduct_research()
report = await researcher.write_report()
```

### Multiple MCP Servers

```python
from gpt_researcher import GPTResearcher

researcher = GPTResearcher(
    query="Analyze the stock performance of Tesla",
    mcp_configs=[
        # Financial data MCP server
        {
            "server_command": "python",
            "server_args": ["financial_mcp_server.py"],
            "tool_name": "get_stock_data"
        },
        # News analysis MCP server
        {
            "server_command": "python",
            "server_args": ["news_mcp_server.py"],
            "tool_name": "search_news"
        }
    ]
)
```

### Remote MCP Server via WebSocket

```python
from gpt_researcher import GPTResearcher

researcher = GPTResearcher(
    query="Latest advancements in AI research",
    mcp_configs=[
        {
            # No need to specify connection_type as it's auto-detected from the URL
            "connection_url": "wss://your-mcp-server.com/ws",
            "connection_token": "your_auth_token",
            "tool_name": "search"
        }
    ]
)
```

### GitHub MCP Server

```python
from gpt_researcher import GPTResearcher
import os

researcher = GPTResearcher(
    query="How does React's useState hook work?",
    mcp_configs=[
        {
            "server_command": "npx",
            "server_args": ["-y", "@modelcontextprotocol/server-github"],
            "tool_name": "searchCode",
            "env": {
                "GITHUB_TOKEN": os.getenv("GITHUB_TOKEN")
            }
        }
    ]
)
```

## Using Multiple Retrievers

You can combine MCP retrievers with traditional web search retrievers:

```python
from gpt_researcher import GPTResearcher

researcher = GPTResearcher(
    query="Impact of climate change on agriculture",
    headers={
        "retrievers": "mcp,tavily",  # Use both MCP and Tavily
        "tavily_api_key": "your_tavily_api_key"
    },
    mcp_configs=[
        {
            "server_command": "python",
            "server_args": ["climate_data_server.py"],
            "tool_name": "get_climate_data"
        }
    ]
)
```

## Tool Selection

By default, GPT Researcher will:

1. Use the tool specified in your configuration (`tool_name`)
2. Use LLM to generate appropriate arguments for the tool based on the current research context
3. Dynamically adjust arguments to be most relevant to the specific query

To enable automatic tool selection instead of using the predefined tool:

```python
# Set environment variable
os.environ["MCP_AUTO_TOOL_SELECTION"] = "true"

# Then create researcher
researcher = GPTResearcher(
    query="your query",
    mcp_configs=[...] 
)
```

With auto tool selection, the LLM will:
1. Examine available tools on the MCP server
2. Select the most appropriate tool for the current research query
3. Generate relevant arguments for that tool
4. Use the tool to retrieve information for the research

## Best Practices

1. **Specify tool names** when you know which specific tool you need
2. **Enable auto tool selection** for more flexible research on servers with multiple tools
3. **Combine multiple MCP servers** for complex research questions
4. **Use environment variables** for sensitive information like API keys
5. **Create custom MCP servers** for specialized knowledge domains

## Automatic Connection Type Detection

GPT Researcher can automatically detect the appropriate connection type based on the URL pattern:

- URLs starting with `wss://` or `ws://` will use WebSocket connection
- URLs starting with `https://` or `http://` will use HTTP connection
- When no URL is provided, stdio connection is used by default (for local servers)

This means you can simply provide the `connection_url` without specifying `connection_type`:

```python
# WebSocket connection (detected from wss:// prefix)
mcp_configs=[{
    "connection_url": "wss://example.com/mcp-ws",
    "tool_name": "search"
}]

# HTTP connection (detected from https:// prefix)
mcp_configs=[{
    "connection_url": "https://example.com/mcp-api",
    "tool_name": "search"
}]
```

You can still explicitly set the `connection_type` if needed to override the automatic detection.

## Migrating from Header-Based Configuration

If you're currently using the header-based approach for MCP configuration, here's how to migrate:

### Old approach:

```python
researcher = GPTResearcher(
    query="your query",
    headers={
        "retriever": "mcp",
        "mcp_server_command": "python",
        "mcp_server_args": "path/to/server.py",
        "mcp_tool_name": "search",
        "mcp_tool_arg_max_results": "5"  # This is no longer needed
    }
)
```

### New approach:

```python
researcher = GPTResearcher(
    query="your query",
    mcp_configs=[
        {
            "server_command": "python",
            "server_args": ["path/to/server.py"],
            "tool_name": "search"
            # No static tool_args - arguments are generated dynamically
        }
    ]
)
```

The new approach is much more maintainable, especially when working with multiple MCP servers or complex configurations. 